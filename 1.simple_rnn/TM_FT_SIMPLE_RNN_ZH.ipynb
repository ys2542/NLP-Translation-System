{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re  \n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from sacrebleu import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_zh = '/home/ys2542/Neural-Translation-System/iwslt-zh-en-processed/'\n",
    "path_vi = '/home/ys2542/Neural-Translation-System/iwslt-vi-en-processed/'\n",
    "ft_home = '/scratch/ys2542/NLP_FASTTEXT/'\n",
    "model_path = '/scratch/ys2542/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "UNK_token = 1\n",
    "SOS_token = 2\n",
    "EOS_token = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_load = 100000 \n",
    "EMBED_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ft_home + 'wiki-news-300d-1M.vec') as f:\n",
    "    matrix_size = words_to_load + 4\n",
    "    loaded_embeddings_ft_en = np.zeros((matrix_size, EMBED_SIZE))\n",
    "    words_ft_en = {'<pad>': PAD_token, '<unk>': UNK_token, '<sos>': SOS_token, '<eos>': EOS_token,}\n",
    "    idx2words_ft_en = {PAD_token: '<pad>', UNK_token: '<unk>', SOS_token: '<sos>', EOS_token: '<eos>'}\n",
    "    ordered_words_ft_en = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "    \n",
    "    loaded_embeddings_ft_en[0,:] = np.zeros(EMBED_SIZE)\n",
    "    loaded_embeddings_ft_en[1,:] = np.random.uniform(-1.0, 1.0, EMBED_SIZE)\n",
    "    loaded_embeddings_ft_en[2,:] = np.random.uniform(-1.0, 1.0, EMBED_SIZE)\n",
    "    loaded_embeddings_ft_en[3,:] = np.random.uniform(-1.0, 1.0, EMBED_SIZE)\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if i == words_to_load + 1: \n",
    "            break\n",
    "        s = line.split()\n",
    "        idx = i + 3\n",
    "        loaded_embeddings_ft_en[idx, :] = np.asarray(s[1:])\n",
    "        words_ft_en[s[0]] = idx\n",
    "        idx2words_ft_en[idx] = s[0]\n",
    "        ordered_words_ft_en.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ft_home + 'cc.zh.300.vec') as f:\n",
    "    matrix_size = words_to_load + 4\n",
    "    loaded_embeddings_ft_zh = np.zeros((matrix_size, EMBED_SIZE))\n",
    "    words_ft_zh = {'<pad>': PAD_token, '<unk>': UNK_token, '<sos>': SOS_token, '<eos>': EOS_token,}\n",
    "    idx2words_ft_zh = {PAD_token: '<pad>', UNK_token: '<unk>', SOS_token: '<sos>', EOS_token: '<eos>'}\n",
    "    ordered_words_ft_zh = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "    \n",
    "    loaded_embeddings_ft_zh[0,:] = np.zeros(EMBED_SIZE)\n",
    "    loaded_embeddings_ft_zh[1,:] = np.random.uniform(-1.0, 1.0, EMBED_SIZE)\n",
    "    loaded_embeddings_ft_zh[2,:] = np.random.uniform(-1.0, 1.0, EMBED_SIZE)\n",
    "    loaded_embeddings_ft_zh[3,:] = np.random.uniform(-1.0, 1.0, EMBED_SIZE)\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if i == words_to_load + 1: \n",
    "            break\n",
    "        s = line.split()\n",
    "        idx = i + 3\n",
    "        loaded_embeddings_ft_zh[idx, :] = np.asarray(s[1:])\n",
    "        words_ft_zh[s[0]] = idx\n",
    "        idx2words_ft_zh[idx] = s[0]\n",
    "        ordered_words_ft_zh.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_zh_train = open(path_zh + 'train.tok.zh', encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_train = open(path_zh + 'train.tok.en', encoding = 'utf-8').read().strip().split('\\n')\n",
    "\n",
    "lines_zh_val = open(path_zh + 'dev.tok.zh', encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_val = open(path_zh + 'dev.tok.en', encoding = 'utf-8').read().strip().split('\\n')\n",
    "\n",
    "lines_zh_test = open(path_zh + 'test.tok.zh', encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_test = open(path_zh + 'test.tok.en', encoding = 'utf-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lines(lines, lang):\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        if line == '':\n",
    "            line = ' '\n",
    "        if lang == 'en':\n",
    "            line = line.replace(\"&apos;\", \"\").replace(\"&quot;\", \"\")\n",
    "        if line[-1] != ' ':\n",
    "            line = line + ' '\n",
    "       \n",
    "        line = '<sos> ' + line + '<eos>'\n",
    "        data.append(line)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zh = clean_lines(lines_zh_train, 'zh')\n",
    "train_en = clean_lines(lines_en_train, 'en')\n",
    "\n",
    "val_zh = clean_lines(lines_zh_val, 'zh')\n",
    "val_en = clean_lines(lines_en_val, 'en')\n",
    "\n",
    "test_zh = clean_lines(lines_zh_test, 'zh')\n",
    "test_en = clean_lines(lines_en_test, 'en')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(data, lang):\n",
    "    indexes = []\n",
    "    for sentence in data:\n",
    "        index = []\n",
    "        for token in sentence.split():\n",
    "            if lang == 'zh':\n",
    "                try:\n",
    "                    index.append(words_ft_zh[token])\n",
    "                except KeyError:\n",
    "                    index.append(UNK_token)\n",
    "            elif lang == 'en':\n",
    "                try:\n",
    "                    index.append(words_ft_en[token])\n",
    "                except KeyError:\n",
    "                    index.append(UNK_token)\n",
    "        indexes.append(index)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zh_indexes = indexesFromSentence(train_zh, 'zh')\n",
    "train_en_indexes = indexesFromSentence(train_en, 'en')\n",
    "\n",
    "val_zh_indexes = indexesFromSentence(val_zh, 'zh')\n",
    "val_en_indexes = indexesFromSentence(val_en, 'en')\n",
    "\n",
    "test_zh_indexes = indexesFromSentence(test_zh, 'zh')\n",
    "test_en_indexes = indexesFromSentence(test_en, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "length_zh = []\n",
    "for line in train_zh_indexes:\n",
    "        length_zh.append(len(line))\n",
    "        \n",
    "length_zh = sorted(length_zh)\n",
    "MAX_LENGTH_ZH = length_zh[int(len(train_zh_indexes)*0.99)]\n",
    "print(MAX_LENGTH_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "length_en = []\n",
    "for line in train_en_indexes:\n",
    "        length_en.append(len(line))\n",
    "        \n",
    "length_zh = sorted(length_en)\n",
    "MAX_LENGTH_EN = length_en[int(len(train_en_indexes)*0.99)]\n",
    "print(MAX_LENGTH_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "length_en = []\n",
    "for line in val_zh_indexes:\n",
    "        length_en.append(len(line))\n",
    "        \n",
    "length_zh = sorted(length_en)\n",
    "MAX_LENGTH_EN = length_en[int(len(val_zh_indexes)*0.99)]\n",
    "print(MAX_LENGTH_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "length_en = []\n",
    "for line in val_en_indexes:\n",
    "        length_en.append(len(line))\n",
    "        \n",
    "length_zh = sorted(length_en)\n",
    "MAX_LENGTH_EN = length_en[int(len(val_en_indexes)*0.99)]\n",
    "print(MAX_LENGTH_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "length_en = []\n",
    "for line in test_zh_indexes:\n",
    "        length_en.append(len(line))\n",
    "        \n",
    "length_zh = sorted(length_en)\n",
    "MAX_LENGTH_EN = length_en[int(len(test_zh_indexes)*0.99)]\n",
    "print(MAX_LENGTH_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "length_en = []\n",
    "for line in test_en_indexes:\n",
    "        length_en.append(len(line))\n",
    "        \n",
    "length_zh = sorted(length_en)\n",
    "MAX_LENGTH_EN = length_en[int(len(test_en_indexes)*0.99)]\n",
    "print(MAX_LENGTH_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH_ZH = 69\n",
    "MAX_LENGTH_EN = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zh_indexes_filtered = []\n",
    "train_en_indexes_filtered = []\n",
    "for i in range(len(train_zh_indexes)):\n",
    "    if len(train_zh_indexes[i]) <= MAX_LENGTH_ZH and len(train_en_indexes[i]) <= MAX_LENGTH_EN:\n",
    "        train_zh_indexes_filtered.append(train_zh_indexes[i])\n",
    "        train_en_indexes_filtered.append(train_en_indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_zh_indexes_filtered = []\n",
    "val_en_indexes_filtered = []\n",
    "for i in range(len(val_zh_indexes)):\n",
    "    if len(val_zh_indexes[i]) <= MAX_LENGTH_ZH and len(val_en_indexes[i]) <= MAX_LENGTH_EN:\n",
    "        val_zh_indexes_filtered.append(val_zh_indexes[i])\n",
    "        val_en_indexes_filtered.append(val_en_indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_zh_indexes_filtered = []\n",
    "test_en_indexes_filtered = []\n",
    "for i in range(len(test_zh_indexes)):\n",
    "    if len(test_zh_indexes[i]) <= MAX_LENGTH_ZH and len(test_en_indexes[i]) <= MAX_LENGTH_EN:\n",
    "        test_zh_indexes_filtered.append(test_zh_indexes[i])\n",
    "        test_en_indexes_filtered.append(test_en_indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabDataset(Dataset):\n",
    "    def __init__(self, data_list1, data_list2):\n",
    "        \n",
    "        self.data_list1 = data_list1\n",
    "        self.data_list2 = data_list2\n",
    "        \n",
    "        assert (len(self.data_list1) == len(self.data_list2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list1)\n",
    "            \n",
    "    def __getitem__(self, key):        \n",
    "        return [self.data_list1[key], self.data_list2[key], len(self.data_list1[key]), len(self.data_list2[key])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    length_list1 = []\n",
    "    length_list2 = []\n",
    "    \n",
    "    for datum in batch:\n",
    "        length_list1.append(datum[2])\n",
    "        length_list2.append(datum[3])\n",
    "        \n",
    "        padded_vec1 = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_LENGTH_ZH-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec2 = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,MAX_LENGTH_EN-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        \n",
    "        data_list1.append(padded_vec1[:MAX_LENGTH_ZH])\n",
    "        data_list2.append(padded_vec2[:MAX_LENGTH_EN])\n",
    "\n",
    "\n",
    "    return [torch.from_numpy(np.array(data_list1)).cuda(), torch.from_numpy(np.array(data_list2)).cuda(),\n",
    "                torch.LongTensor(length_list1).cuda(), torch.LongTensor(length_list2).cuda()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = VocabDataset(train_zh_indexes_filtered, train_en_indexes_filtered)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = VocabDataset(val_zh_indexes_filtered, val_en_indexes_filtered)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = VocabDataset(test_zh_indexes_filtered, test_en_indexes_filtered)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "val_loader2 = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_size=EMBED_SIZE):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(loaded_embeddings_ft_zh).float(), freeze=True)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embed_size=EMBED_SIZE):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(loaded_embeddings_ft_en).float(), freeze=True)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input)        \n",
    "        output = F.relu(output)        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    batch_size, input_length = input_tensor.size()\n",
    "    _, target_length = target_tensor.size()\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    decoder_input = torch.tensor(np.array([[SOS_token]] * batch_size).reshape(1, batch_size), device=device)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "        \n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "            decoder_input = target_tensor[:,di].unsqueeze(0) \n",
    "            \n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "                        \n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  \n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    " \n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "            \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=100, plot_every=100, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    \n",
    "    plot_losses_t = []\n",
    "    print_loss_total_t = 0  \n",
    "    plot_loss_total_t = 0  \n",
    "    \n",
    "    plot_losses_v = []\n",
    "    print_loss_total_v = 0  \n",
    "    plot_loss_total_v = 0 \n",
    "    \n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (data1, data2, length1, length2) in enumerate(train_loader):\n",
    "            input_tensor = data1\n",
    "            target_tensor = data2\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total_t += loss\n",
    "            plot_loss_total_t += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total_t / print_every\n",
    "                print_loss_total_t = 0\n",
    "                print('Train %s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total_t / plot_every\n",
    "                plot_losses_t.append(plot_loss_avg)\n",
    "                plot_loss_total_t = 0\n",
    "                \n",
    "        for i, (data1, data2, length1, length2) in enumerate(val_loader):\n",
    "            input_tensor = data1\n",
    "            target_tensor = data2\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total_v += loss\n",
    "            plot_loss_total_v += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total_v / print_every\n",
    "                print_loss_total_v = 0\n",
    "                print('Val %s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total_v / plot_every\n",
    "                plot_losses_v.append(plot_loss_avg)\n",
    "                plot_loss_total_v = 0\n",
    "                \n",
    "        torch.save(encoder.state_dict(), model_path + \"encoder_rnn\"+str(hidden_size)+str(iter)+\".pth\")\n",
    "        torch.save(decoder.state_dict(), model_path + \"decoder_rnn\"+str(hidden_size)+str(iter)+\".pth\")\n",
    "\n",
    "    return plot_losses_t, plot_losses_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0m 0s (- 0m 2s) (1 12%) 0.1152\n",
      "Train 0m 23s (- 2m 47s) (1 12%) 4.1645\n",
      "Train 0m 47s (- 5m 31s) (1 12%) 3.0805\n",
      "Train 1m 10s (- 8m 15s) (1 12%) 3.0577\n",
      "Train 1m 34s (- 10m 59s) (1 12%) 2.9110\n",
      "Train 1m 57s (- 13m 45s) (1 12%) 2.8814\n",
      "Train 2m 21s (- 16m 29s) (1 12%) 2.8007\n",
      "Train 2m 44s (- 19m 14s) (1 12%) 2.7399\n",
      "Train 3m 8s (- 21m 59s) (1 12%) 2.7419\n",
      "Train 3m 32s (- 24m 44s) (1 12%) 2.6945\n",
      "Train 3m 55s (- 27m 29s) (1 12%) 2.6910\n",
      "Train 4m 19s (- 30m 14s) (1 12%) 2.6832\n",
      "Train 4m 42s (- 32m 59s) (1 12%) 2.6682\n",
      "Train 5m 6s (- 35m 45s) (1 12%) 2.6939\n",
      "Train 5m 30s (- 38m 31s) (1 12%) 2.7058\n",
      "Train 5m 53s (- 41m 16s) (1 12%) 2.6407\n",
      "Train 6m 17s (- 44m 1s) (1 12%) 2.6068\n",
      "Train 6m 41s (- 46m 47s) (1 12%) 2.6212\n",
      "Train 7m 4s (- 49m 33s) (1 12%) 2.5993\n",
      "Train 7m 28s (- 52m 18s) (1 12%) 2.5270\n",
      "Train 7m 51s (- 55m 2s) (1 12%) 2.5155\n",
      "Train 8m 15s (- 57m 48s) (1 12%) 2.5658\n",
      "Train 8m 38s (- 60m 32s) (1 12%) 2.4874\n",
      "Train 9m 2s (- 63m 17s) (1 12%) 2.5728\n",
      "Train 9m 26s (- 66m 2s) (1 12%) 2.5148\n",
      "Train 9m 49s (- 68m 45s) (1 12%) 2.4584\n",
      "Train 10m 13s (- 71m 31s) (1 12%) 2.4993\n",
      "Train 10m 36s (- 74m 16s) (1 12%) 2.5423\n",
      "Train 11m 0s (- 77m 1s) (1 12%) 2.4808\n",
      "Train 11m 23s (- 79m 45s) (1 12%) 2.4483\n",
      "Train 11m 47s (- 82m 31s) (1 12%) 2.4625\n",
      "Train 12m 10s (- 85m 15s) (1 12%) 2.4142\n",
      "Train 12m 34s (- 88m 1s) (1 12%) 2.5206\n",
      "Train 12m 58s (- 90m 46s) (1 12%) 2.4487\n",
      "Train 13m 21s (- 93m 32s) (1 12%) 2.4617\n",
      "Train 13m 45s (- 96m 17s) (1 12%) 2.4864\n",
      "Train 14m 8s (- 99m 2s) (1 12%) 2.4153\n",
      "Train 14m 32s (- 101m 47s) (1 12%) 2.4382\n",
      "Train 14m 56s (- 104m 32s) (1 12%) 2.4356\n",
      "Train 15m 19s (- 107m 18s) (1 12%) 2.4049\n",
      "Train 15m 43s (- 110m 5s) (1 12%) 2.5576\n",
      "Train 16m 7s (- 112m 51s) (1 12%) 2.4398\n",
      "Train 16m 30s (- 115m 35s) (1 12%) 2.3288\n",
      "Train 16m 54s (- 118m 21s) (1 12%) 2.3886\n",
      "Train 17m 17s (- 121m 5s) (1 12%) 2.4125\n",
      "Train 17m 41s (- 123m 51s) (1 12%) 2.3994\n",
      "Train 18m 5s (- 126m 35s) (1 12%) 2.3978\n",
      "Train 18m 28s (- 129m 20s) (1 12%) 2.3594\n",
      "Train 18m 52s (- 132m 4s) (1 12%) 2.3241\n",
      "Train 19m 15s (- 134m 49s) (1 12%) 2.3623\n",
      "Train 19m 39s (- 137m 35s) (1 12%) 2.3787\n",
      "Train 20m 2s (- 140m 20s) (1 12%) 2.4418\n",
      "Train 20m 26s (- 143m 5s) (1 12%) 2.3515\n",
      "Train 20m 50s (- 145m 50s) (1 12%) 2.3656\n",
      "Train 21m 13s (- 148m 33s) (1 12%) 2.2581\n",
      "Train 21m 36s (- 151m 18s) (1 12%) 2.3915\n",
      "Train 22m 0s (- 154m 3s) (1 12%) 2.3575\n",
      "Train 22m 24s (- 156m 49s) (1 12%) 2.3811\n",
      "Train 22m 47s (- 159m 34s) (1 12%) 2.3808\n",
      "Train 23m 11s (- 162m 21s) (1 12%) 2.4209\n",
      "Train 23m 35s (- 165m 7s) (1 12%) 2.4133\n",
      "Val 23m 36s (- 165m 12s) (1 12%) 0.0229\n",
      "Train 23m 46s (- 71m 18s) (2 25%) 0.0573\n",
      "Train 24m 9s (- 72m 29s) (2 25%) 2.3019\n",
      "Train 24m 33s (- 73m 39s) (2 25%) 2.2729\n",
      "Train 24m 56s (- 74m 50s) (2 25%) 2.3653\n",
      "Train 25m 20s (- 76m 1s) (2 25%) 2.3025\n",
      "Train 25m 44s (- 77m 12s) (2 25%) 2.3385\n",
      "Train 26m 7s (- 78m 23s) (2 25%) 2.2858\n",
      "Train 26m 31s (- 79m 34s) (2 25%) 2.3242\n",
      "Train 26m 55s (- 80m 45s) (2 25%) 2.3181\n",
      "Train 27m 18s (- 81m 56s) (2 25%) 2.3084\n",
      "Train 27m 42s (- 83m 7s) (2 25%) 2.2992\n",
      "Train 28m 6s (- 84m 18s) (2 25%) 2.2830\n",
      "Train 28m 29s (- 85m 29s) (2 25%) 2.3486\n",
      "Train 28m 53s (- 86m 39s) (2 25%) 2.2582\n",
      "Train 29m 16s (- 87m 50s) (2 25%) 2.2702\n",
      "Train 29m 40s (- 89m 1s) (2 25%) 2.2404\n",
      "Train 30m 3s (- 90m 11s) (2 25%) 2.2353\n",
      "Train 30m 27s (- 91m 21s) (2 25%) 2.2094\n",
      "Train 30m 50s (- 92m 32s) (2 25%) 2.2609\n",
      "Train 31m 14s (- 93m 43s) (2 25%) 2.3045\n",
      "Train 31m 38s (- 94m 54s) (2 25%) 2.2855\n",
      "Train 32m 1s (- 96m 5s) (2 25%) 2.2648\n",
      "Train 32m 25s (- 97m 15s) (2 25%) 2.2009\n",
      "Train 32m 49s (- 98m 27s) (2 25%) 2.3219\n",
      "Train 33m 12s (- 99m 37s) (2 25%) 2.2434\n",
      "Train 33m 36s (- 100m 48s) (2 25%) 2.2933\n",
      "Train 33m 59s (- 101m 59s) (2 25%) 2.3221\n",
      "Train 34m 23s (- 103m 10s) (2 25%) 2.2485\n",
      "Train 34m 47s (- 104m 21s) (2 25%) 2.2196\n",
      "Train 35m 10s (- 105m 32s) (2 25%) 2.2070\n",
      "Train 35m 34s (- 106m 43s) (2 25%) 2.2215\n",
      "Train 35m 58s (- 107m 54s) (2 25%) 2.2694\n",
      "Train 36m 21s (- 109m 5s) (2 25%) 2.2783\n",
      "Train 36m 45s (- 110m 16s) (2 25%) 2.2170\n",
      "Train 37m 8s (- 111m 26s) (2 25%) 2.1920\n",
      "Train 37m 32s (- 112m 37s) (2 25%) 2.1786\n",
      "Train 37m 55s (- 113m 47s) (2 25%) 2.2119\n",
      "Train 38m 19s (- 114m 59s) (2 25%) 2.2737\n",
      "Train 38m 43s (- 116m 10s) (2 25%) 2.2605\n",
      "Train 39m 7s (- 117m 21s) (2 25%) 2.2034\n",
      "Train 39m 30s (- 118m 32s) (2 25%) 2.2161\n",
      "Train 39m 54s (- 119m 42s) (2 25%) 2.1242\n",
      "Train 40m 17s (- 120m 53s) (2 25%) 2.2805\n",
      "Train 40m 41s (- 122m 3s) (2 25%) 2.1982\n",
      "Train 41m 4s (- 123m 14s) (2 25%) 2.2193\n",
      "Train 41m 28s (- 124m 25s) (2 25%) 2.2031\n",
      "Train 41m 52s (- 125m 36s) (2 25%) 2.1883\n",
      "Train 42m 15s (- 126m 47s) (2 25%) 2.2860\n",
      "Train 42m 39s (- 127m 57s) (2 25%) 2.1146\n",
      "Train 43m 2s (- 129m 8s) (2 25%) 2.2403\n",
      "Train 43m 26s (- 130m 19s) (2 25%) 2.2533\n",
      "Train 43m 50s (- 131m 30s) (2 25%) 2.1984\n",
      "Train 44m 13s (- 132m 40s) (2 25%) 2.1358\n",
      "Train 44m 36s (- 133m 50s) (2 25%) 2.1892\n",
      "Train 45m 0s (- 135m 1s) (2 25%) 2.2632\n",
      "Train 45m 24s (- 136m 12s) (2 25%) 2.2221\n",
      "Train 45m 47s (- 137m 23s) (2 25%) 2.1835\n",
      "Train 46m 11s (- 138m 34s) (2 25%) 2.1782\n",
      "Train 46m 34s (- 139m 44s) (2 25%) 2.1968\n",
      "Train 46m 58s (- 140m 55s) (2 25%) 2.1306\n",
      "Train 47m 22s (- 142m 6s) (2 25%) 2.1838\n",
      "Val 47m 22s (- 142m 8s) (2 25%) 0.8784\n",
      "Train 47m 32s (- 79m 14s) (3 37%) 0.0569\n",
      "Train 47m 55s (- 79m 53s) (3 37%) 2.0800\n",
      "Train 48m 19s (- 80m 32s) (3 37%) 2.2481\n",
      "Train 48m 43s (- 81m 12s) (3 37%) 2.0797\n",
      "Train 49m 6s (- 81m 51s) (3 37%) 2.1592\n",
      "Train 49m 30s (- 82m 30s) (3 37%) 2.1553\n",
      "Train 49m 54s (- 83m 10s) (3 37%) 2.1569\n",
      "Train 50m 17s (- 83m 49s) (3 37%) 2.1473\n",
      "Train 50m 41s (- 84m 29s) (3 37%) 2.1270\n",
      "Train 51m 4s (- 85m 8s) (3 37%) 2.1143\n",
      "Train 51m 28s (- 85m 47s) (3 37%) 2.0637\n",
      "Train 51m 51s (- 86m 26s) (3 37%) 2.0570\n",
      "Train 52m 15s (- 87m 5s) (3 37%) 2.1532\n",
      "Train 52m 39s (- 87m 45s) (3 37%) 2.0466\n",
      "Train 53m 2s (- 88m 24s) (3 37%) 2.1247\n",
      "Train 53m 26s (- 89m 3s) (3 37%) 2.1764\n",
      "Train 53m 49s (- 89m 42s) (3 37%) 2.1048\n",
      "Train 54m 13s (- 90m 22s) (3 37%) 2.1248\n",
      "Train 54m 37s (- 91m 2s) (3 37%) 2.1570\n",
      "Train 55m 0s (- 91m 41s) (3 37%) 2.1244\n",
      "Train 55m 24s (- 92m 20s) (3 37%) 2.1351\n",
      "Train 55m 47s (- 92m 59s) (3 37%) 2.1582\n",
      "Train 56m 11s (- 93m 39s) (3 37%) 2.0518\n",
      "Train 56m 34s (- 94m 18s) (3 37%) 2.0955\n",
      "Train 56m 58s (- 94m 57s) (3 37%) 2.1352\n",
      "Train 57m 22s (- 95m 37s) (3 37%) 2.1517\n",
      "Train 57m 45s (- 96m 16s) (3 37%) 2.1268\n",
      "Train 58m 9s (- 96m 56s) (3 37%) 2.1753\n",
      "Train 58m 33s (- 97m 35s) (3 37%) 2.0709\n",
      "Train 58m 56s (- 98m 14s) (3 37%) 2.1301\n",
      "Train 59m 20s (- 98m 53s) (3 37%) 2.1717\n",
      "Train 59m 43s (- 99m 33s) (3 37%) 2.1460\n",
      "Train 60m 7s (- 100m 12s) (3 37%) 2.1229\n",
      "Train 60m 30s (- 100m 51s) (3 37%) 2.0561\n",
      "Train 60m 54s (- 101m 30s) (3 37%) 2.0971\n",
      "Train 61m 17s (- 102m 9s) (3 37%) 2.1027\n",
      "Train 61m 41s (- 102m 49s) (3 37%) 2.1219\n",
      "Train 62m 5s (- 103m 28s) (3 37%) 2.1487\n",
      "Train 62m 28s (- 104m 7s) (3 37%) 2.1064\n",
      "Train 62m 52s (- 104m 47s) (3 37%) 2.1007\n",
      "Train 63m 16s (- 105m 26s) (3 37%) 2.1528\n",
      "Train 63m 39s (- 106m 6s) (3 37%) 2.1786\n",
      "Train 64m 3s (- 106m 45s) (3 37%) 2.1489\n",
      "Train 64m 27s (- 107m 25s) (3 37%) 2.1098\n",
      "Train 64m 50s (- 108m 4s) (3 37%) 2.0896\n",
      "Train 65m 14s (- 108m 43s) (3 37%) 2.1308\n",
      "Train 65m 37s (- 109m 23s) (3 37%) 2.1139\n",
      "Train 66m 1s (- 110m 2s) (3 37%) 2.0755\n",
      "Train 66m 24s (- 110m 41s) (3 37%) 2.1281\n",
      "Train 66m 48s (- 111m 20s) (3 37%) 2.1116\n",
      "Train 67m 11s (- 111m 59s) (3 37%) 2.0590\n",
      "Train 67m 35s (- 112m 38s) (3 37%) 2.1219\n",
      "Train 67m 59s (- 113m 18s) (3 37%) 2.1529\n",
      "Train 68m 22s (- 113m 57s) (3 37%) 2.0733\n",
      "Train 68m 46s (- 114m 37s) (3 37%) 2.1806\n",
      "Train 69m 9s (- 115m 16s) (3 37%) 2.0907\n",
      "Train 69m 33s (- 115m 55s) (3 37%) 2.1176\n",
      "Train 69m 57s (- 116m 35s) (3 37%) 2.1073\n",
      "Train 70m 20s (- 117m 14s) (3 37%) 2.0777\n",
      "Train 70m 44s (- 117m 53s) (3 37%) 2.1006\n",
      "Train 71m 7s (- 118m 32s) (3 37%) 2.0340\n",
      "Val 71m 8s (- 118m 33s) (3 37%) 0.8316\n",
      "Train 71m 17s (- 71m 17s) (4 50%) 0.0519\n",
      "Train 71m 41s (- 71m 41s) (4 50%) 2.0788\n",
      "Train 72m 4s (- 72m 4s) (4 50%) 1.9483\n",
      "Train 72m 28s (- 72m 28s) (4 50%) 2.0400\n",
      "Train 72m 52s (- 72m 52s) (4 50%) 2.0264\n",
      "Train 73m 15s (- 73m 15s) (4 50%) 1.9949\n",
      "Train 73m 39s (- 73m 39s) (4 50%) 2.0276\n",
      "Train 74m 2s (- 74m 2s) (4 50%) 2.1151\n",
      "Train 74m 26s (- 74m 26s) (4 50%) 2.0036\n",
      "Train 74m 49s (- 74m 49s) (4 50%) 2.0520\n",
      "Train 75m 13s (- 75m 13s) (4 50%) 2.0344\n",
      "Train 75m 37s (- 75m 37s) (4 50%) 2.0418\n",
      "Train 76m 0s (- 76m 0s) (4 50%) 2.0844\n",
      "Train 76m 24s (- 76m 24s) (4 50%) 2.0711\n",
      "Train 76m 48s (- 76m 48s) (4 50%) 2.0902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 77m 11s (- 77m 11s) (4 50%) 2.0061\n",
      "Train 77m 35s (- 77m 35s) (4 50%) 2.0553\n",
      "Train 77m 58s (- 77m 58s) (4 50%) 2.0877\n",
      "Train 78m 22s (- 78m 22s) (4 50%) 2.0159\n",
      "Train 78m 45s (- 78m 45s) (4 50%) 1.9751\n",
      "Train 79m 9s (- 79m 9s) (4 50%) 2.0879\n",
      "Train 79m 33s (- 79m 33s) (4 50%) 2.0783\n",
      "Train 79m 56s (- 79m 56s) (4 50%) 2.0105\n",
      "Train 80m 20s (- 80m 20s) (4 50%) 2.0449\n",
      "Train 80m 43s (- 80m 43s) (4 50%) 1.9733\n",
      "Train 81m 7s (- 81m 7s) (4 50%) 2.1212\n",
      "Train 81m 31s (- 81m 31s) (4 50%) 2.1075\n",
      "Train 81m 54s (- 81m 54s) (4 50%) 2.0083\n",
      "Train 82m 18s (- 82m 18s) (4 50%) 2.0472\n",
      "Train 82m 42s (- 82m 42s) (4 50%) 2.1188\n",
      "Train 83m 5s (- 83m 5s) (4 50%) 2.0813\n",
      "Train 83m 29s (- 83m 29s) (4 50%) 2.0989\n",
      "Train 83m 53s (- 83m 53s) (4 50%) 2.0296\n",
      "Train 84m 16s (- 84m 16s) (4 50%) 2.0695\n",
      "Train 84m 40s (- 84m 40s) (4 50%) 2.0571\n",
      "Train 85m 3s (- 85m 3s) (4 50%) 2.0400\n",
      "Train 85m 27s (- 85m 27s) (4 50%) 2.0776\n",
      "Train 85m 51s (- 85m 51s) (4 50%) 2.0540\n",
      "Train 86m 14s (- 86m 14s) (4 50%) 2.0614\n",
      "Train 86m 38s (- 86m 38s) (4 50%) 2.0056\n",
      "Train 87m 2s (- 87m 2s) (4 50%) 2.0436\n",
      "Train 87m 25s (- 87m 25s) (4 50%) 2.0467\n",
      "Train 87m 49s (- 87m 49s) (4 50%) 2.0549\n",
      "Train 88m 12s (- 88m 12s) (4 50%) 2.0287\n",
      "Train 88m 36s (- 88m 36s) (4 50%) 1.9802\n",
      "Train 88m 59s (- 88m 59s) (4 50%) 2.0131\n",
      "Train 89m 23s (- 89m 23s) (4 50%) 2.0619\n",
      "Train 89m 46s (- 89m 46s) (4 50%) 2.0460\n",
      "Train 90m 10s (- 90m 10s) (4 50%) 2.0774\n",
      "Train 90m 34s (- 90m 34s) (4 50%) 2.0039\n",
      "Train 90m 57s (- 90m 57s) (4 50%) 2.1622\n",
      "Train 91m 21s (- 91m 21s) (4 50%) 2.0478\n",
      "Train 91m 45s (- 91m 45s) (4 50%) 2.0222\n",
      "Train 92m 8s (- 92m 8s) (4 50%) 2.0787\n",
      "Train 92m 32s (- 92m 32s) (4 50%) 2.1117\n",
      "Train 92m 56s (- 92m 56s) (4 50%) 2.0685\n",
      "Train 93m 19s (- 93m 19s) (4 50%) 2.0497\n",
      "Train 93m 43s (- 93m 43s) (4 50%) 2.1074\n",
      "Train 94m 7s (- 94m 7s) (4 50%) 2.0588\n",
      "Train 94m 30s (- 94m 30s) (4 50%) 2.0764\n",
      "Train 94m 54s (- 94m 54s) (4 50%) 2.0338\n",
      "Val 94m 54s (- 94m 54s) (4 50%) 0.7664\n",
      "Train 95m 4s (- 57m 2s) (5 62%) 0.0472\n",
      "Train 95m 28s (- 57m 16s) (5 62%) 2.0484\n",
      "Train 95m 51s (- 57m 31s) (5 62%) 2.0164\n",
      "Train 96m 15s (- 57m 45s) (5 62%) 1.9352\n",
      "Train 96m 39s (- 57m 59s) (5 62%) 1.9656\n",
      "Train 97m 2s (- 58m 13s) (5 62%) 1.8797\n",
      "Train 97m 26s (- 58m 27s) (5 62%) 2.0045\n",
      "Train 97m 49s (- 58m 41s) (5 62%) 1.9583\n",
      "Train 98m 13s (- 58m 55s) (5 62%) 1.9826\n",
      "Train 98m 36s (- 59m 10s) (5 62%) 1.9808\n",
      "Train 99m 0s (- 59m 24s) (5 62%) 1.9103\n",
      "Train 99m 23s (- 59m 38s) (5 62%) 1.9667\n",
      "Train 99m 47s (- 59m 52s) (5 62%) 1.9457\n",
      "Train 100m 11s (- 60m 6s) (5 62%) 2.0185\n",
      "Train 100m 34s (- 60m 20s) (5 62%) 1.9188\n",
      "Train 100m 58s (- 60m 34s) (5 62%) 2.0165\n",
      "Train 101m 21s (- 60m 49s) (5 62%) 1.9847\n",
      "Train 101m 45s (- 61m 3s) (5 62%) 1.9421\n",
      "Train 102m 8s (- 61m 17s) (5 62%) 1.9594\n",
      "Train 102m 32s (- 61m 31s) (5 62%) 2.0143\n",
      "Train 102m 55s (- 61m 45s) (5 62%) 1.9073\n",
      "Train 103m 19s (- 61m 59s) (5 62%) 2.0627\n",
      "Train 103m 43s (- 62m 13s) (5 62%) 1.9660\n",
      "Train 104m 6s (- 62m 28s) (5 62%) 2.0478\n",
      "Train 104m 30s (- 62m 42s) (5 62%) 1.9599\n",
      "Train 104m 54s (- 62m 56s) (5 62%) 1.9845\n",
      "Train 105m 17s (- 63m 10s) (5 62%) 1.9875\n",
      "Train 105m 41s (- 63m 24s) (5 62%) 1.9778\n",
      "Train 106m 4s (- 63m 38s) (5 62%) 2.0293\n",
      "Train 106m 28s (- 63m 53s) (5 62%) 2.0237\n",
      "Train 106m 52s (- 64m 7s) (5 62%) 2.0164\n",
      "Train 107m 15s (- 64m 21s) (5 62%) 2.0072\n",
      "Train 107m 39s (- 64m 35s) (5 62%) 1.9772\n",
      "Train 108m 3s (- 64m 49s) (5 62%) 2.0174\n",
      "Train 108m 26s (- 65m 3s) (5 62%) 1.9619\n",
      "Train 108m 49s (- 65m 17s) (5 62%) 1.9131\n",
      "Train 109m 13s (- 65m 32s) (5 62%) 1.9639\n",
      "Train 109m 36s (- 65m 46s) (5 62%) 1.9783\n",
      "Train 110m 0s (- 66m 0s) (5 62%) 1.9941\n",
      "Train 110m 23s (- 66m 14s) (5 62%) 1.9899\n",
      "Train 110m 47s (- 66m 28s) (5 62%) 2.0833\n",
      "Train 111m 11s (- 66m 42s) (5 62%) 2.0493\n",
      "Train 111m 34s (- 66m 56s) (5 62%) 1.9772\n",
      "Train 111m 58s (- 67m 11s) (5 62%) 1.9598\n",
      "Train 112m 22s (- 67m 25s) (5 62%) 2.0463\n",
      "Train 112m 46s (- 67m 39s) (5 62%) 2.0699\n",
      "Train 113m 9s (- 67m 53s) (5 62%) 2.0545\n",
      "Train 113m 33s (- 68m 7s) (5 62%) 1.9568\n",
      "Train 113m 57s (- 68m 22s) (5 62%) 2.0522\n",
      "Train 114m 20s (- 68m 36s) (5 62%) 2.0635\n",
      "Train 114m 44s (- 68m 50s) (5 62%) 1.9345\n",
      "Train 115m 7s (- 69m 4s) (5 62%) 2.0014\n",
      "Train 115m 31s (- 69m 18s) (5 62%) 2.0058\n",
      "Train 115m 54s (- 69m 32s) (5 62%) 2.0013\n",
      "Train 116m 18s (- 69m 47s) (5 62%) 2.0440\n",
      "Train 116m 42s (- 70m 1s) (5 62%) 2.0166\n",
      "Train 117m 5s (- 70m 15s) (5 62%) 1.9984\n",
      "Train 117m 29s (- 70m 29s) (5 62%) 2.0304\n",
      "Train 117m 53s (- 70m 43s) (5 62%) 2.1192\n",
      "Train 118m 16s (- 70m 58s) (5 62%) 2.0513\n",
      "Train 118m 40s (- 71m 12s) (5 62%) 2.0337\n",
      "Val 118m 41s (- 71m 12s) (5 62%) 0.7404\n",
      "Train 118m 50s (- 39m 36s) (6 75%) 0.0536\n",
      "Train 119m 14s (- 39m 44s) (6 75%) 1.9398\n",
      "Train 119m 37s (- 39m 52s) (6 75%) 1.9395\n",
      "Train 120m 1s (- 40m 0s) (6 75%) 1.9254\n",
      "Train 120m 24s (- 40m 8s) (6 75%) 1.9226\n",
      "Train 120m 48s (- 40m 16s) (6 75%) 1.8953\n",
      "Train 121m 12s (- 40m 24s) (6 75%) 1.9228\n",
      "Train 121m 35s (- 40m 31s) (6 75%) 1.9155\n",
      "Train 121m 59s (- 40m 39s) (6 75%) 1.8487\n",
      "Train 122m 22s (- 40m 47s) (6 75%) 1.9559\n",
      "Train 122m 46s (- 40m 55s) (6 75%) 1.9312\n",
      "Train 123m 9s (- 41m 3s) (6 75%) 1.9435\n",
      "Train 123m 33s (- 41m 11s) (6 75%) 1.9339\n",
      "Train 123m 57s (- 41m 19s) (6 75%) 1.9347\n",
      "Train 124m 20s (- 41m 26s) (6 75%) 1.8938\n",
      "Train 124m 43s (- 41m 34s) (6 75%) 1.9225\n",
      "Train 125m 7s (- 41m 42s) (6 75%) 1.9535\n",
      "Train 125m 31s (- 41m 50s) (6 75%) 1.9290\n",
      "Train 125m 54s (- 41m 58s) (6 75%) 1.9268\n",
      "Train 126m 18s (- 42m 6s) (6 75%) 1.9342\n",
      "Train 126m 41s (- 42m 13s) (6 75%) 1.9077\n",
      "Train 127m 5s (- 42m 21s) (6 75%) 1.9119\n",
      "Train 127m 28s (- 42m 29s) (6 75%) 1.8912\n",
      "Train 127m 52s (- 42m 37s) (6 75%) 1.9652\n",
      "Train 128m 15s (- 42m 45s) (6 75%) 1.9529\n",
      "Train 128m 39s (- 42m 53s) (6 75%) 1.9608\n",
      "Train 129m 2s (- 43m 0s) (6 75%) 1.9422\n",
      "Train 129m 26s (- 43m 8s) (6 75%) 2.0161\n",
      "Train 129m 50s (- 43m 16s) (6 75%) 1.9680\n",
      "Train 130m 13s (- 43m 24s) (6 75%) 1.8682\n",
      "Train 130m 37s (- 43m 32s) (6 75%) 1.9676\n",
      "Train 131m 0s (- 43m 40s) (6 75%) 1.9509\n",
      "Train 131m 24s (- 43m 48s) (6 75%) 1.9680\n",
      "Train 131m 48s (- 43m 56s) (6 75%) 1.9364\n",
      "Train 132m 11s (- 44m 3s) (6 75%) 1.8799\n",
      "Train 132m 35s (- 44m 11s) (6 75%) 1.9696\n",
      "Train 132m 58s (- 44m 19s) (6 75%) 1.9576\n",
      "Train 133m 22s (- 44m 27s) (6 75%) 1.9189\n",
      "Train 133m 46s (- 44m 35s) (6 75%) 2.0519\n",
      "Train 134m 9s (- 44m 43s) (6 75%) 1.9981\n",
      "Train 134m 33s (- 44m 51s) (6 75%) 1.9512\n",
      "Train 134m 57s (- 44m 59s) (6 75%) 2.0043\n",
      "Train 135m 20s (- 45m 6s) (6 75%) 1.9156\n",
      "Train 135m 44s (- 45m 14s) (6 75%) 1.9441\n",
      "Train 136m 8s (- 45m 22s) (6 75%) 2.0248\n",
      "Train 136m 31s (- 45m 30s) (6 75%) 1.9634\n",
      "Train 136m 55s (- 45m 38s) (6 75%) 1.9143\n",
      "Train 137m 18s (- 45m 46s) (6 75%) 1.9353\n",
      "Train 137m 42s (- 45m 54s) (6 75%) 1.9557\n",
      "Train 138m 5s (- 46m 1s) (6 75%) 1.9365\n",
      "Train 138m 29s (- 46m 9s) (6 75%) 2.0051\n",
      "Train 138m 53s (- 46m 17s) (6 75%) 2.0098\n",
      "Train 139m 16s (- 46m 25s) (6 75%) 1.9794\n",
      "Train 139m 40s (- 46m 33s) (6 75%) 2.0133\n",
      "Train 140m 4s (- 46m 41s) (6 75%) 1.9481\n",
      "Train 140m 27s (- 46m 49s) (6 75%) 1.9374\n",
      "Train 140m 50s (- 46m 56s) (6 75%) 1.9259\n",
      "Train 141m 14s (- 47m 4s) (6 75%) 2.0285\n",
      "Train 141m 38s (- 47m 12s) (6 75%) 2.0242\n",
      "Train 142m 1s (- 47m 20s) (6 75%) 1.9444\n",
      "Train 142m 25s (- 47m 28s) (6 75%) 1.9213\n",
      "Val 142m 26s (- 47m 28s) (6 75%) 0.7139\n",
      "Train 142m 35s (- 20m 22s) (7 87%) 0.0621\n",
      "Train 142m 59s (- 20m 25s) (7 87%) 1.8666\n",
      "Train 143m 22s (- 20m 28s) (7 87%) 1.9180\n",
      "Train 143m 45s (- 20m 32s) (7 87%) 1.9016\n",
      "Train 144m 9s (- 20m 35s) (7 87%) 1.8784\n",
      "Train 144m 33s (- 20m 39s) (7 87%) 1.8148\n",
      "Train 144m 57s (- 20m 42s) (7 87%) 1.8929\n",
      "Train 145m 20s (- 20m 45s) (7 87%) 1.8412\n",
      "Train 145m 44s (- 20m 49s) (7 87%) 1.9554\n",
      "Train 146m 8s (- 20m 52s) (7 87%) 1.9406\n",
      "Train 146m 32s (- 20m 56s) (7 87%) 1.9529\n",
      "Train 146m 56s (- 20m 59s) (7 87%) 1.9555\n",
      "Train 147m 20s (- 21m 2s) (7 87%) 1.9050\n",
      "Train 147m 43s (- 21m 6s) (7 87%) 1.8587\n",
      "Train 148m 7s (- 21m 9s) (7 87%) 1.9581\n",
      "Train 148m 31s (- 21m 13s) (7 87%) 1.9172\n",
      "Train 148m 55s (- 21m 16s) (7 87%) 1.9647\n",
      "Train 149m 19s (- 21m 19s) (7 87%) 1.8618\n",
      "Train 149m 43s (- 21m 23s) (7 87%) 1.8693\n",
      "Train 150m 6s (- 21m 26s) (7 87%) 1.8450\n",
      "Train 150m 30s (- 21m 30s) (7 87%) 1.9021\n",
      "Train 150m 54s (- 21m 33s) (7 87%) 1.9349\n",
      "Train 151m 17s (- 21m 36s) (7 87%) 1.8726\n",
      "Train 151m 41s (- 21m 40s) (7 87%) 1.8962\n",
      "Train 152m 5s (- 21m 43s) (7 87%) 1.9442\n",
      "Train 152m 29s (- 21m 47s) (7 87%) 1.9066\n",
      "Train 152m 53s (- 21m 50s) (7 87%) 1.9485\n",
      "Train 153m 17s (- 21m 53s) (7 87%) 1.9351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 153m 40s (- 21m 57s) (7 87%) 1.9350\n",
      "Train 154m 4s (- 22m 0s) (7 87%) 1.9187\n",
      "Train 154m 28s (- 22m 4s) (7 87%) 1.8831\n",
      "Train 154m 52s (- 22m 7s) (7 87%) 1.9611\n",
      "Train 155m 15s (- 22m 10s) (7 87%) 1.8745\n",
      "Train 155m 39s (- 22m 14s) (7 87%) 1.8598\n",
      "Train 156m 3s (- 22m 17s) (7 87%) 1.9812\n",
      "Train 156m 27s (- 22m 21s) (7 87%) 1.9965\n",
      "Train 156m 50s (- 22m 24s) (7 87%) 1.9167\n",
      "Train 157m 14s (- 22m 27s) (7 87%) 1.9191\n",
      "Train 157m 38s (- 22m 31s) (7 87%) 1.9325\n",
      "Train 158m 2s (- 22m 34s) (7 87%) 1.9726\n",
      "Train 158m 26s (- 22m 38s) (7 87%) 1.8684\n",
      "Train 158m 50s (- 22m 41s) (7 87%) 1.9682\n",
      "Train 159m 13s (- 22m 44s) (7 87%) 1.8859\n",
      "Train 159m 37s (- 22m 48s) (7 87%) 1.9781\n",
      "Train 160m 1s (- 22m 51s) (7 87%) 1.9053\n",
      "Train 160m 25s (- 22m 55s) (7 87%) 1.9375\n",
      "Train 160m 49s (- 22m 58s) (7 87%) 1.9706\n",
      "Train 161m 12s (- 23m 1s) (7 87%) 1.9506\n",
      "Train 161m 36s (- 23m 5s) (7 87%) 1.8982\n",
      "Train 162m 0s (- 23m 8s) (7 87%) 2.0102\n",
      "Train 162m 24s (- 23m 12s) (7 87%) 1.9674\n",
      "Train 162m 47s (- 23m 15s) (7 87%) 1.8127\n",
      "Train 163m 11s (- 23m 18s) (7 87%) 1.9324\n",
      "Train 163m 35s (- 23m 22s) (7 87%) 1.9111\n",
      "Train 163m 59s (- 23m 25s) (7 87%) 1.9333\n",
      "Train 164m 23s (- 23m 29s) (7 87%) 1.9673\n",
      "Train 164m 47s (- 23m 32s) (7 87%) 2.0003\n",
      "Train 165m 10s (- 23m 35s) (7 87%) 1.9734\n",
      "Train 165m 34s (- 23m 39s) (7 87%) 1.9330\n",
      "Train 165m 58s (- 23m 42s) (7 87%) 1.9827\n",
      "Train 166m 22s (- 23m 46s) (7 87%) 1.9484\n",
      "Val 166m 23s (- 23m 46s) (7 87%) 0.7094\n",
      "Train 166m 32s (- 0m 0s) (8 100%) 0.0669\n",
      "Train 166m 56s (- 0m 0s) (8 100%) 1.8885\n",
      "Train 167m 20s (- 0m 0s) (8 100%) 1.9314\n",
      "Train 167m 44s (- 0m 0s) (8 100%) 1.8480\n",
      "Train 168m 8s (- 0m 0s) (8 100%) 1.8166\n",
      "Train 168m 31s (- 0m 0s) (8 100%) 1.8010\n",
      "Train 168m 55s (- 0m 0s) (8 100%) 1.8548\n",
      "Train 169m 19s (- 0m 0s) (8 100%) 1.8765\n",
      "Train 169m 43s (- 0m 0s) (8 100%) 1.8319\n",
      "Train 170m 7s (- 0m 0s) (8 100%) 1.8784\n",
      "Train 170m 30s (- 0m 0s) (8 100%) 1.8804\n",
      "Train 170m 54s (- 0m 0s) (8 100%) 1.8573\n",
      "Train 171m 18s (- 0m 0s) (8 100%) 1.8739\n",
      "Train 171m 42s (- 0m 0s) (8 100%) 1.8234\n",
      "Train 172m 6s (- 0m 0s) (8 100%) 1.8950\n",
      "Train 172m 29s (- 0m 0s) (8 100%) 1.9136\n",
      "Train 172m 53s (- 0m 0s) (8 100%) 1.8543\n",
      "Train 173m 17s (- 0m 0s) (8 100%) 1.8365\n",
      "Train 173m 40s (- 0m 0s) (8 100%) 1.8878\n",
      "Train 174m 4s (- 0m 0s) (8 100%) 1.8002\n",
      "Train 174m 28s (- 0m 0s) (8 100%) 1.9813\n",
      "Train 174m 52s (- 0m 0s) (8 100%) 1.8954\n",
      "Train 175m 16s (- 0m 0s) (8 100%) 1.9446\n",
      "Train 175m 39s (- 0m 0s) (8 100%) 1.8470\n",
      "Train 176m 3s (- 0m 0s) (8 100%) 1.9599\n",
      "Train 176m 27s (- 0m 0s) (8 100%) 1.9122\n",
      "Train 176m 51s (- 0m 0s) (8 100%) 1.8243\n",
      "Train 177m 15s (- 0m 0s) (8 100%) 1.9319\n",
      "Train 177m 39s (- 0m 0s) (8 100%) 1.9291\n",
      "Train 178m 3s (- 0m 0s) (8 100%) 1.9138\n",
      "Train 178m 27s (- 0m 0s) (8 100%) 1.9154\n",
      "Train 178m 50s (- 0m 0s) (8 100%) 1.9083\n",
      "Train 179m 14s (- 0m 0s) (8 100%) 1.8834\n",
      "Train 179m 38s (- 0m 0s) (8 100%) 1.9643\n",
      "Train 180m 2s (- 0m 0s) (8 100%) 1.9161\n",
      "Train 180m 26s (- 0m 0s) (8 100%) 1.9281\n",
      "Train 180m 50s (- 0m 0s) (8 100%) 1.8737\n",
      "Train 181m 13s (- 0m 0s) (8 100%) 1.8750\n",
      "Train 181m 37s (- 0m 0s) (8 100%) 1.8350\n",
      "Train 182m 1s (- 0m 0s) (8 100%) 1.8904\n",
      "Train 182m 24s (- 0m 0s) (8 100%) 1.9101\n",
      "Train 182m 48s (- 0m 0s) (8 100%) 1.9105\n",
      "Train 183m 12s (- 0m 0s) (8 100%) 1.8579\n",
      "Train 183m 36s (- 0m 0s) (8 100%) 1.9177\n",
      "Train 184m 0s (- 0m 0s) (8 100%) 1.8864\n",
      "Train 184m 23s (- 0m 0s) (8 100%) 1.9645\n",
      "Train 184m 47s (- 0m 0s) (8 100%) 1.8520\n",
      "Train 185m 11s (- 0m 0s) (8 100%) 1.8735\n",
      "Train 185m 35s (- 0m 0s) (8 100%) 1.9232\n",
      "Train 185m 59s (- 0m 0s) (8 100%) 1.9594\n",
      "Train 186m 22s (- 0m 0s) (8 100%) 1.8328\n",
      "Train 186m 46s (- 0m 0s) (8 100%) 1.9166\n",
      "Train 187m 10s (- 0m 0s) (8 100%) 1.9475\n",
      "Train 187m 33s (- 0m 0s) (8 100%) 1.8970\n",
      "Train 187m 57s (- 0m 0s) (8 100%) 1.9422\n",
      "Train 188m 20s (- 0m 0s) (8 100%) 1.9524\n",
      "Train 188m 44s (- 0m 0s) (8 100%) 1.9134\n",
      "Train 189m 7s (- 0m 0s) (8 100%) 1.9178\n",
      "Train 189m 30s (- 0m 0s) (8 100%) 1.8188\n",
      "Train 189m 54s (- 0m 0s) (8 100%) 1.9852\n",
      "Train 190m 17s (- 0m 0s) (8 100%) 1.8126\n",
      "Val 190m 18s (- 0m 0s) (8 100%) 0.6771\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 300\n",
    "encoder1 = EncoderRNN(hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, len(ordered_words_ft_zh)).to(device)\n",
    "\n",
    "plotloss_t1, plotloss_v1 = trainIters(encoder1, decoder1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0m 0s (- 0m 2s) (1 12%) 0.1152\n",
      "Train 0m 32s (- 3m 50s) (1 12%) 3.8326\n",
      "Train 1m 5s (- 7m 38s) (1 12%) 3.1646\n",
      "Train 1m 38s (- 11m 27s) (1 12%) 3.0939\n",
      "Train 2m 10s (- 15m 16s) (1 12%) 2.9944\n",
      "Train 2m 43s (- 19m 4s) (1 12%) 2.9968\n",
      "Train 3m 16s (- 22m 53s) (1 12%) 2.8880\n",
      "Train 3m 48s (- 26m 42s) (1 12%) 2.8758\n",
      "Train 4m 21s (- 30m 32s) (1 12%) 2.7768\n",
      "Train 4m 54s (- 34m 20s) (1 12%) 2.6888\n",
      "Train 5m 27s (- 38m 10s) (1 12%) 2.7078\n",
      "Train 5m 59s (- 41m 59s) (1 12%) 2.6730\n",
      "Train 6m 32s (- 45m 46s) (1 12%) 2.6266\n",
      "Train 7m 5s (- 49m 36s) (1 12%) 2.6702\n",
      "Train 7m 37s (- 53m 25s) (1 12%) 2.6743\n",
      "Train 8m 10s (- 57m 15s) (1 12%) 2.6176\n",
      "Train 8m 43s (- 61m 2s) (1 12%) 2.5297\n",
      "Train 9m 15s (- 64m 51s) (1 12%) 2.5838\n",
      "Train 9m 48s (- 68m 42s) (1 12%) 2.6313\n",
      "Train 10m 21s (- 72m 31s) (1 12%) 2.5707\n",
      "Train 10m 54s (- 76m 21s) (1 12%) 2.5861\n",
      "Train 11m 27s (- 80m 9s) (1 12%) 2.4847\n",
      "Train 11m 59s (- 83m 58s) (1 12%) 2.5022\n",
      "Train 12m 32s (- 87m 46s) (1 12%) 2.4826\n",
      "Train 13m 5s (- 91m 35s) (1 12%) 2.4960\n",
      "Train 13m 37s (- 95m 23s) (1 12%) 2.4890\n",
      "Train 14m 10s (- 99m 12s) (1 12%) 2.4753\n",
      "Train 14m 43s (- 103m 1s) (1 12%) 2.4882\n",
      "Train 15m 16s (- 106m 53s) (1 12%) 2.5746\n",
      "Train 15m 48s (- 110m 42s) (1 12%) 2.4903\n",
      "Train 16m 21s (- 114m 31s) (1 12%) 2.4535\n",
      "Train 16m 54s (- 118m 19s) (1 12%) 2.4391\n",
      "Train 17m 27s (- 122m 9s) (1 12%) 2.5054\n",
      "Train 17m 59s (- 125m 58s) (1 12%) 2.4287\n",
      "Train 18m 32s (- 129m 48s) (1 12%) 2.4682\n",
      "Train 19m 5s (- 133m 36s) (1 12%) 2.3991\n",
      "Train 19m 37s (- 137m 25s) (1 12%) 2.4552\n",
      "Train 20m 10s (- 141m 13s) (1 12%) 2.3967\n",
      "Train 20m 43s (- 145m 1s) (1 12%) 2.3123\n",
      "Train 21m 15s (- 148m 50s) (1 12%) 2.4492\n",
      "Train 21m 48s (- 152m 38s) (1 12%) 2.3825\n",
      "Train 22m 21s (- 156m 27s) (1 12%) 2.4149\n",
      "Train 22m 53s (- 160m 16s) (1 12%) 2.4075\n",
      "Train 23m 26s (- 164m 5s) (1 12%) 2.3793\n",
      "Train 23m 59s (- 167m 56s) (1 12%) 2.4906\n",
      "Train 24m 32s (- 171m 46s) (1 12%) 2.4198\n",
      "Train 25m 4s (- 175m 33s) (1 12%) 2.2762\n",
      "Train 25m 37s (- 179m 22s) (1 12%) 2.3845\n",
      "Train 26m 10s (- 183m 11s) (1 12%) 2.4426\n",
      "Train 26m 42s (- 187m 0s) (1 12%) 2.2917\n",
      "Train 27m 15s (- 190m 48s) (1 12%) 2.3311\n",
      "Train 27m 48s (- 194m 38s) (1 12%) 2.3651\n",
      "Train 28m 20s (- 198m 26s) (1 12%) 2.3133\n",
      "Train 28m 53s (- 202m 16s) (1 12%) 2.3714\n",
      "Train 29m 26s (- 206m 6s) (1 12%) 2.4353\n",
      "Train 29m 59s (- 209m 56s) (1 12%) 2.3692\n",
      "Train 30m 32s (- 213m 45s) (1 12%) 2.3421\n",
      "Train 31m 4s (- 217m 34s) (1 12%) 2.3342\n",
      "Train 31m 37s (- 221m 22s) (1 12%) 2.3561\n",
      "Train 32m 10s (- 225m 11s) (1 12%) 2.2915\n",
      "Train 32m 43s (- 229m 1s) (1 12%) 2.3120\n",
      "Val 32m 44s (- 229m 8s) (1 12%) 0.0252\n",
      "Train 32m 57s (- 98m 51s) (2 25%) 0.0654\n",
      "Train 33m 30s (- 100m 30s) (2 25%) 2.3022\n",
      "Train 34m 2s (- 102m 8s) (2 25%) 2.2994\n",
      "Train 34m 35s (- 103m 46s) (2 25%) 2.3014\n",
      "Train 35m 8s (- 105m 24s) (2 25%) 2.2806\n",
      "Train 35m 40s (- 107m 2s) (2 25%) 2.2881\n",
      "Train 36m 13s (- 108m 41s) (2 25%) 2.3618\n",
      "Train 36m 46s (- 110m 18s) (2 25%) 2.1671\n",
      "Train 37m 18s (- 111m 56s) (2 25%) 2.2228\n",
      "Train 37m 51s (- 113m 35s) (2 25%) 2.3183\n",
      "Train 38m 24s (- 115m 12s) (2 25%) 2.2688\n",
      "Train 38m 56s (- 116m 49s) (2 25%) 2.2362\n",
      "Train 39m 28s (- 118m 26s) (2 25%) 2.2226\n",
      "Train 40m 0s (- 120m 2s) (2 25%) 2.1905\n",
      "Train 40m 33s (- 121m 40s) (2 25%) 2.2663\n",
      "Train 41m 5s (- 123m 17s) (2 25%) 2.2589\n",
      "Train 41m 38s (- 124m 54s) (2 25%) 2.1957\n",
      "Train 42m 10s (- 126m 31s) (2 25%) 2.2513\n",
      "Train 42m 42s (- 128m 8s) (2 25%) 2.3018\n",
      "Train 43m 15s (- 129m 46s) (2 25%) 2.2986\n",
      "Train 43m 47s (- 131m 23s) (2 25%) 2.1958\n",
      "Train 44m 20s (- 133m 0s) (2 25%) 2.2573\n",
      "Train 44m 52s (- 134m 37s) (2 25%) 2.3113\n",
      "Train 45m 24s (- 136m 14s) (2 25%) 2.2383\n",
      "Train 45m 57s (- 137m 51s) (2 25%) 2.2397\n",
      "Train 46m 29s (- 139m 29s) (2 25%) 2.2320\n",
      "Train 47m 2s (- 141m 6s) (2 25%) 2.2741\n",
      "Train 47m 34s (- 142m 44s) (2 25%) 2.2640\n",
      "Train 48m 7s (- 144m 21s) (2 25%) 2.1912\n",
      "Train 48m 39s (- 145m 58s) (2 25%) 2.2564\n",
      "Train 49m 11s (- 147m 35s) (2 25%) 2.2172\n",
      "Train 49m 44s (- 149m 12s) (2 25%) 2.2248\n",
      "Train 50m 16s (- 150m 49s) (2 25%) 2.2215\n",
      "Train 50m 48s (- 152m 26s) (2 25%) 2.2716\n",
      "Train 51m 21s (- 154m 3s) (2 25%) 2.2288\n",
      "Train 51m 53s (- 155m 40s) (2 25%) 2.1787\n",
      "Train 52m 25s (- 157m 17s) (2 25%) 2.1542\n",
      "Train 52m 58s (- 158m 54s) (2 25%) 2.1541\n",
      "Train 53m 30s (- 160m 31s) (2 25%) 2.2516\n",
      "Train 54m 2s (- 162m 8s) (2 25%) 2.1868\n",
      "Train 54m 35s (- 163m 45s) (2 25%) 2.1944\n",
      "Train 55m 7s (- 165m 22s) (2 25%) 2.2539\n",
      "Train 55m 39s (- 166m 59s) (2 25%) 2.1521\n",
      "Train 56m 12s (- 168m 36s) (2 25%) 2.2051\n",
      "Train 56m 44s (- 170m 13s) (2 25%) 2.1959\n",
      "Train 57m 17s (- 171m 51s) (2 25%) 2.2872\n",
      "Train 57m 49s (- 173m 27s) (2 25%) 2.1180\n",
      "Train 58m 21s (- 175m 4s) (2 25%) 2.1349\n",
      "Train 58m 53s (- 176m 41s) (2 25%) 2.2331\n",
      "Train 59m 26s (- 178m 19s) (2 25%) 2.2283\n",
      "Train 59m 58s (- 179m 56s) (2 25%) 2.1943\n",
      "Train 60m 31s (- 181m 33s) (2 25%) 2.2534\n",
      "Train 61m 3s (- 183m 10s) (2 25%) 2.1821\n",
      "Train 61m 35s (- 184m 47s) (2 25%) 2.1400\n",
      "Train 62m 8s (- 186m 24s) (2 25%) 2.2001\n",
      "Train 62m 40s (- 188m 1s) (2 25%) 2.1448\n",
      "Train 63m 12s (- 189m 38s) (2 25%) 2.1173\n",
      "Train 63m 45s (- 191m 15s) (2 25%) 2.1618\n",
      "Train 64m 17s (- 192m 52s) (2 25%) 2.1288\n",
      "Train 64m 49s (- 194m 29s) (2 25%) 2.2796\n",
      "Train 65m 22s (- 196m 6s) (2 25%) 2.1627\n",
      "Val 65m 23s (- 196m 9s) (2 25%) 0.8546\n",
      "Train 65m 36s (- 109m 20s) (3 37%) 0.0729\n",
      "Train 66m 8s (- 110m 14s) (3 37%) 2.1029\n",
      "Train 66m 40s (- 111m 8s) (3 37%) 2.1120\n",
      "Train 67m 13s (- 112m 2s) (3 37%) 2.1693\n",
      "Train 67m 45s (- 112m 56s) (3 37%) 2.1191\n",
      "Train 68m 18s (- 113m 50s) (3 37%) 2.1708\n",
      "Train 68m 50s (- 114m 44s) (3 37%) 2.1536\n",
      "Train 69m 23s (- 115m 38s) (3 37%) 2.1181\n",
      "Train 69m 55s (- 116m 32s) (3 37%) 2.0784\n",
      "Train 70m 27s (- 117m 26s) (3 37%) 2.1249\n",
      "Train 70m 59s (- 118m 19s) (3 37%) 2.0272\n",
      "Train 71m 32s (- 119m 13s) (3 37%) 2.1810\n",
      "Train 72m 4s (- 120m 7s) (3 37%) 2.1068\n",
      "Train 72m 37s (- 121m 1s) (3 37%) 2.0707\n",
      "Train 73m 9s (- 121m 55s) (3 37%) 2.1138\n",
      "Train 73m 41s (- 122m 49s) (3 37%) 2.0993\n",
      "Train 74m 13s (- 123m 43s) (3 37%) 2.0437\n",
      "Train 74m 46s (- 124m 36s) (3 37%) 2.0620\n",
      "Train 75m 18s (- 125m 30s) (3 37%) 2.0990\n",
      "Train 75m 50s (- 126m 24s) (3 37%) 2.1949\n",
      "Train 76m 23s (- 127m 18s) (3 37%) 2.1405\n",
      "Train 76m 55s (- 128m 12s) (3 37%) 2.1413\n",
      "Train 77m 28s (- 129m 6s) (3 37%) 2.1280\n",
      "Train 78m 0s (- 130m 0s) (3 37%) 2.1684\n",
      "Train 78m 32s (- 130m 54s) (3 37%) 2.1148\n",
      "Train 79m 5s (- 131m 48s) (3 37%) 2.1032\n",
      "Train 79m 37s (- 132m 42s) (3 37%) 2.1195\n",
      "Train 80m 10s (- 133m 37s) (3 37%) 2.2287\n",
      "Train 80m 42s (- 134m 30s) (3 37%) 2.0494\n",
      "Train 81m 15s (- 135m 25s) (3 37%) 2.1738\n",
      "Train 81m 47s (- 136m 19s) (3 37%) 2.1421\n",
      "Train 82m 19s (- 137m 13s) (3 37%) 2.1232\n",
      "Train 82m 52s (- 138m 6s) (3 37%) 2.0959\n",
      "Train 83m 24s (- 139m 1s) (3 37%) 2.2037\n",
      "Train 83m 57s (- 139m 55s) (3 37%) 2.1012\n",
      "Train 84m 29s (- 140m 49s) (3 37%) 2.1773\n",
      "Train 85m 1s (- 141m 43s) (3 37%) 2.0424\n",
      "Train 85m 34s (- 142m 37s) (3 37%) 2.1462\n",
      "Train 86m 6s (- 143m 31s) (3 37%) 2.1537\n",
      "Train 86m 39s (- 144m 25s) (3 37%) 2.1445\n",
      "Train 87m 11s (- 145m 19s) (3 37%) 2.1168\n",
      "Train 87m 44s (- 146m 13s) (3 37%) 2.1488\n",
      "Train 88m 16s (- 147m 7s) (3 37%) 2.0662\n",
      "Train 88m 48s (- 148m 1s) (3 37%) 2.1122\n",
      "Train 89m 20s (- 148m 54s) (3 37%) 2.0879\n",
      "Train 89m 53s (- 149m 48s) (3 37%) 2.0996\n",
      "Train 90m 25s (- 150m 42s) (3 37%) 2.1007\n",
      "Train 90m 57s (- 151m 36s) (3 37%) 2.0996\n",
      "Train 91m 30s (- 152m 30s) (3 37%) 2.0623\n",
      "Train 92m 2s (- 153m 24s) (3 37%) 2.1107\n",
      "Train 92m 34s (- 154m 18s) (3 37%) 2.0042\n",
      "Train 93m 7s (- 155m 12s) (3 37%) 2.1456\n",
      "Train 93m 39s (- 156m 6s) (3 37%) 2.0885\n",
      "Train 94m 12s (- 157m 0s) (3 37%) 2.1003\n",
      "Train 94m 44s (- 157m 54s) (3 37%) 2.0366\n",
      "Train 95m 16s (- 158m 48s) (3 37%) 2.1161\n",
      "Train 95m 49s (- 159m 41s) (3 37%) 2.0648\n",
      "Train 96m 21s (- 160m 35s) (3 37%) 2.1148\n",
      "Train 96m 53s (- 161m 29s) (3 37%) 2.0816\n",
      "Train 97m 26s (- 162m 23s) (3 37%) 2.0687\n",
      "Train 97m 58s (- 163m 17s) (3 37%) 2.0578\n",
      "Val 97m 59s (- 163m 19s) (3 37%) 0.7839\n",
      "Train 98m 12s (- 98m 12s) (4 50%) 0.0688\n",
      "Train 98m 44s (- 98m 44s) (4 50%) 2.0124\n",
      "Train 99m 16s (- 99m 16s) (4 50%) 1.9797\n",
      "Train 99m 49s (- 99m 49s) (4 50%) 2.0443\n",
      "Train 100m 21s (- 100m 21s) (4 50%) 2.0722\n",
      "Train 100m 54s (- 100m 54s) (4 50%) 2.0582\n",
      "Train 101m 26s (- 101m 26s) (4 50%) 1.9898\n",
      "Train 101m 58s (- 101m 58s) (4 50%) 2.0220\n",
      "Train 102m 31s (- 102m 31s) (4 50%) 2.0312\n",
      "Train 103m 3s (- 103m 3s) (4 50%) 2.0788\n",
      "Train 103m 35s (- 103m 35s) (4 50%) 2.0057\n",
      "Train 104m 8s (- 104m 8s) (4 50%) 2.0928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 104m 40s (- 104m 40s) (4 50%) 2.0620\n",
      "Train 105m 12s (- 105m 12s) (4 50%) 1.9694\n",
      "Train 105m 45s (- 105m 45s) (4 50%) 1.9470\n",
      "Train 106m 17s (- 106m 17s) (4 50%) 1.9949\n",
      "Train 106m 49s (- 106m 49s) (4 50%) 1.9926\n",
      "Train 107m 21s (- 107m 21s) (4 50%) 2.0671\n",
      "Train 107m 54s (- 107m 54s) (4 50%) 1.9304\n",
      "Train 108m 26s (- 108m 26s) (4 50%) 2.0938\n",
      "Train 108m 58s (- 108m 58s) (4 50%) 2.0257\n",
      "Train 109m 31s (- 109m 31s) (4 50%) 2.0039\n",
      "Train 110m 3s (- 110m 3s) (4 50%) 2.0173\n",
      "Train 110m 35s (- 110m 35s) (4 50%) 2.0363\n",
      "Train 111m 8s (- 111m 8s) (4 50%) 2.0476\n",
      "Train 111m 40s (- 111m 40s) (4 50%) 2.0954\n",
      "Train 112m 13s (- 112m 13s) (4 50%) 2.0327\n",
      "Train 112m 45s (- 112m 45s) (4 50%) 2.0231\n",
      "Train 113m 17s (- 113m 17s) (4 50%) 2.0051\n",
      "Train 113m 49s (- 113m 49s) (4 50%) 1.9303\n",
      "Train 114m 22s (- 114m 22s) (4 50%) 2.0366\n",
      "Train 114m 54s (- 114m 54s) (4 50%) 2.0439\n",
      "Train 115m 26s (- 115m 26s) (4 50%) 2.0047\n",
      "Train 115m 59s (- 115m 59s) (4 50%) 2.1280\n",
      "Train 116m 31s (- 116m 31s) (4 50%) 2.0368\n",
      "Train 117m 4s (- 117m 4s) (4 50%) 2.0274\n",
      "Train 117m 36s (- 117m 36s) (4 50%) 2.0236\n",
      "Train 118m 9s (- 118m 9s) (4 50%) 2.0762\n",
      "Train 118m 41s (- 118m 41s) (4 50%) 2.0390\n",
      "Train 119m 13s (- 119m 13s) (4 50%) 2.0488\n",
      "Train 119m 46s (- 119m 46s) (4 50%) 2.0968\n",
      "Train 120m 18s (- 120m 18s) (4 50%) 2.0161\n",
      "Train 120m 51s (- 120m 51s) (4 50%) 2.0949\n",
      "Train 121m 23s (- 121m 23s) (4 50%) 2.0456\n",
      "Train 121m 55s (- 121m 55s) (4 50%) 2.0048\n",
      "Train 122m 28s (- 122m 28s) (4 50%) 2.0950\n",
      "Train 123m 0s (- 123m 0s) (4 50%) 2.0223\n",
      "Train 123m 33s (- 123m 33s) (4 50%) 2.0900\n",
      "Train 124m 5s (- 124m 5s) (4 50%) 2.1120\n",
      "Train 124m 38s (- 124m 38s) (4 50%) 2.1172\n",
      "Train 125m 10s (- 125m 10s) (4 50%) 2.0030\n",
      "Train 125m 42s (- 125m 42s) (4 50%) 1.9929\n",
      "Train 126m 15s (- 126m 15s) (4 50%) 2.0545\n",
      "Train 126m 47s (- 126m 47s) (4 50%) 1.9954\n",
      "Train 127m 19s (- 127m 19s) (4 50%) 2.0453\n",
      "Train 127m 51s (- 127m 51s) (4 50%) 1.9553\n",
      "Train 128m 24s (- 128m 24s) (4 50%) 2.0876\n",
      "Train 128m 56s (- 128m 56s) (4 50%) 2.0331\n",
      "Train 129m 29s (- 129m 29s) (4 50%) 2.0976\n",
      "Train 130m 1s (- 130m 1s) (4 50%) 2.0107\n",
      "Train 130m 33s (- 130m 33s) (4 50%) 2.0482\n",
      "Val 130m 34s (- 130m 34s) (4 50%) 0.7822\n",
      "Train 130m 48s (- 78m 28s) (5 62%) 0.0706\n",
      "Train 131m 20s (- 78m 48s) (5 62%) 1.9341\n",
      "Train 131m 52s (- 79m 7s) (5 62%) 2.0253\n",
      "Train 132m 25s (- 79m 27s) (5 62%) 2.0285\n",
      "Train 132m 57s (- 79m 46s) (5 62%) 1.9026\n",
      "Train 133m 30s (- 80m 6s) (5 62%) 1.9407\n",
      "Train 134m 2s (- 80m 25s) (5 62%) 1.8916\n",
      "Train 134m 34s (- 80m 44s) (5 62%) 1.9751\n",
      "Train 135m 7s (- 81m 4s) (5 62%) 2.0295\n",
      "Train 135m 39s (- 81m 23s) (5 62%) 1.9891\n",
      "Train 136m 11s (- 81m 42s) (5 62%) 1.8717\n",
      "Train 136m 44s (- 82m 2s) (5 62%) 1.9833\n",
      "Train 137m 16s (- 82m 21s) (5 62%) 1.9506\n",
      "Train 137m 48s (- 82m 41s) (5 62%) 1.9740\n",
      "Train 138m 20s (- 83m 0s) (5 62%) 1.9565\n",
      "Train 138m 53s (- 83m 20s) (5 62%) 1.9957\n",
      "Train 139m 25s (- 83m 39s) (5 62%) 1.9624\n",
      "Train 139m 58s (- 83m 58s) (5 62%) 1.8900\n",
      "Train 140m 30s (- 84m 18s) (5 62%) 1.9571\n",
      "Train 141m 2s (- 84m 37s) (5 62%) 1.9697\n",
      "Train 141m 34s (- 84m 56s) (5 62%) 1.9496\n",
      "Train 142m 7s (- 85m 16s) (5 62%) 2.0520\n",
      "Train 142m 39s (- 85m 35s) (5 62%) 1.9768\n",
      "Train 143m 12s (- 85m 55s) (5 62%) 2.0228\n",
      "Train 143m 44s (- 86m 14s) (5 62%) 1.9843\n",
      "Train 144m 17s (- 86m 34s) (5 62%) 1.9762\n",
      "Train 144m 49s (- 86m 53s) (5 62%) 1.9063\n",
      "Train 145m 21s (- 87m 12s) (5 62%) 1.9784\n",
      "Train 145m 53s (- 87m 32s) (5 62%) 1.9071\n",
      "Train 146m 26s (- 87m 51s) (5 62%) 1.9645\n",
      "Train 146m 58s (- 88m 11s) (5 62%) 2.0435\n",
      "Train 147m 30s (- 88m 30s) (5 62%) 1.9693\n",
      "Train 148m 3s (- 88m 50s) (5 62%) 2.0689\n",
      "Train 148m 35s (- 89m 9s) (5 62%) 2.0075\n",
      "Train 149m 8s (- 89m 29s) (5 62%) 2.0274\n",
      "Train 149m 40s (- 89m 48s) (5 62%) 2.0613\n",
      "Train 150m 13s (- 90m 7s) (5 62%) 2.0178\n",
      "Train 150m 45s (- 90m 27s) (5 62%) 2.0341\n",
      "Train 151m 18s (- 90m 46s) (5 62%) 2.0528\n",
      "Train 151m 50s (- 91m 6s) (5 62%) 1.9715\n",
      "Train 152m 22s (- 91m 25s) (5 62%) 2.0057\n",
      "Train 152m 55s (- 91m 45s) (5 62%) 2.0029\n",
      "Train 153m 27s (- 92m 4s) (5 62%) 1.9589\n",
      "Train 153m 59s (- 92m 23s) (5 62%) 1.9700\n",
      "Train 154m 32s (- 92m 43s) (5 62%) 1.8985\n",
      "Train 155m 4s (- 93m 2s) (5 62%) 2.0597\n",
      "Train 155m 36s (- 93m 22s) (5 62%) 1.9013\n",
      "Train 156m 9s (- 93m 41s) (5 62%) 1.8975\n",
      "Train 156m 41s (- 94m 0s) (5 62%) 1.9333\n",
      "Train 157m 13s (- 94m 20s) (5 62%) 1.9651\n",
      "Train 157m 45s (- 94m 39s) (5 62%) 2.0071\n",
      "Train 158m 18s (- 94m 58s) (5 62%) 2.0140\n",
      "Train 158m 50s (- 95m 18s) (5 62%) 1.9856\n",
      "Train 159m 22s (- 95m 37s) (5 62%) 1.9340\n",
      "Train 159m 55s (- 95m 57s) (5 62%) 1.9688\n",
      "Train 160m 27s (- 96m 16s) (5 62%) 1.9951\n",
      "Train 160m 59s (- 96m 35s) (5 62%) 1.9917\n",
      "Train 161m 32s (- 96m 55s) (5 62%) 2.0117\n",
      "Train 162m 4s (- 97m 14s) (5 62%) 2.0456\n",
      "Train 162m 37s (- 97m 34s) (5 62%) 1.9669\n",
      "Train 163m 9s (- 97m 53s) (5 62%) 1.9461\n",
      "Val 163m 10s (- 97m 54s) (5 62%) 0.7600\n",
      "Train 163m 23s (- 54m 27s) (6 75%) 0.0717\n",
      "Train 163m 56s (- 54m 38s) (6 75%) 1.9654\n",
      "Train 164m 28s (- 54m 49s) (6 75%) 1.9197\n",
      "Train 165m 1s (- 55m 0s) (6 75%) 1.9342\n",
      "Train 165m 33s (- 55m 11s) (6 75%) 1.8064\n",
      "Train 166m 5s (- 55m 21s) (6 75%) 1.8919\n",
      "Train 166m 37s (- 55m 32s) (6 75%) 1.8128\n",
      "Train 167m 10s (- 55m 43s) (6 75%) 1.8819\n",
      "Train 167m 42s (- 55m 54s) (6 75%) 1.8984\n",
      "Train 168m 14s (- 56m 4s) (6 75%) 1.8944\n",
      "Train 168m 46s (- 56m 15s) (6 75%) 1.7877\n",
      "Train 169m 19s (- 56m 26s) (6 75%) 1.9950\n",
      "Train 169m 51s (- 56m 37s) (6 75%) 1.9030\n",
      "Train 170m 24s (- 56m 48s) (6 75%) 1.8620\n",
      "Train 170m 56s (- 56m 58s) (6 75%) 1.8639\n",
      "Train 171m 28s (- 57m 9s) (6 75%) 1.8603\n",
      "Train 172m 1s (- 57m 20s) (6 75%) 1.9496\n",
      "Train 172m 33s (- 57m 31s) (6 75%) 1.8862\n",
      "Train 173m 5s (- 57m 41s) (6 75%) 2.0068\n",
      "Train 173m 37s (- 57m 52s) (6 75%) 1.8839\n",
      "Train 174m 10s (- 58m 3s) (6 75%) 1.9219\n",
      "Train 174m 42s (- 58m 14s) (6 75%) 1.9542\n",
      "Train 175m 14s (- 58m 24s) (6 75%) 1.9033\n",
      "Train 175m 47s (- 58m 35s) (6 75%) 1.9686\n",
      "Train 176m 19s (- 58m 46s) (6 75%) 1.8330\n",
      "Train 176m 51s (- 58m 57s) (6 75%) 1.9488\n",
      "Train 177m 23s (- 59m 7s) (6 75%) 1.8844\n",
      "Train 177m 56s (- 59m 18s) (6 75%) 1.9665\n",
      "Train 178m 28s (- 59m 29s) (6 75%) 1.9474\n",
      "Train 179m 1s (- 59m 40s) (6 75%) 1.9761\n",
      "Train 179m 33s (- 59m 51s) (6 75%) 1.9253\n",
      "Train 180m 5s (- 60m 1s) (6 75%) 1.9045\n",
      "Train 180m 38s (- 60m 12s) (6 75%) 1.9627\n",
      "Train 181m 10s (- 60m 23s) (6 75%) 1.9127\n",
      "Train 181m 42s (- 60m 34s) (6 75%) 1.9278\n",
      "Train 182m 15s (- 60m 45s) (6 75%) 1.9342\n",
      "Train 182m 47s (- 60m 55s) (6 75%) 1.9743\n",
      "Train 183m 19s (- 61m 6s) (6 75%) 1.9323\n",
      "Train 183m 52s (- 61m 17s) (6 75%) 1.8947\n",
      "Train 184m 24s (- 61m 28s) (6 75%) 1.9395\n",
      "Train 184m 57s (- 61m 39s) (6 75%) 1.9778\n",
      "Train 185m 29s (- 61m 49s) (6 75%) 1.9742\n",
      "Train 186m 1s (- 62m 0s) (6 75%) 1.9202\n",
      "Train 186m 34s (- 62m 11s) (6 75%) 1.9579\n",
      "Train 187m 6s (- 62m 22s) (6 75%) 1.9433\n",
      "Train 187m 38s (- 62m 32s) (6 75%) 1.9263\n",
      "Train 188m 11s (- 62m 43s) (6 75%) 1.9390\n",
      "Train 188m 43s (- 62m 54s) (6 75%) 1.9183\n",
      "Train 189m 15s (- 63m 5s) (6 75%) 1.9246\n",
      "Train 189m 48s (- 63m 16s) (6 75%) 1.9993\n",
      "Train 190m 20s (- 63m 26s) (6 75%) 2.0004\n",
      "Train 190m 53s (- 63m 37s) (6 75%) 2.0140\n",
      "Train 191m 25s (- 63m 48s) (6 75%) 1.8914\n",
      "Train 191m 57s (- 63m 59s) (6 75%) 1.9436\n",
      "Train 192m 30s (- 64m 10s) (6 75%) 1.9457\n",
      "Train 193m 2s (- 64m 20s) (6 75%) 1.9432\n",
      "Train 193m 34s (- 64m 31s) (6 75%) 1.9634\n",
      "Train 194m 7s (- 64m 42s) (6 75%) 1.9418\n",
      "Train 194m 39s (- 64m 53s) (6 75%) 1.9727\n",
      "Train 195m 11s (- 65m 3s) (6 75%) 1.9975\n",
      "Train 195m 44s (- 65m 14s) (6 75%) 1.9097\n",
      "Val 195m 45s (- 65m 15s) (6 75%) 0.7252\n",
      "Train 195m 57s (- 27m 59s) (7 87%) 0.0365\n",
      "Train 196m 30s (- 28m 4s) (7 87%) 1.9109\n",
      "Train 197m 2s (- 28m 8s) (7 87%) 1.7877\n",
      "Train 197m 35s (- 28m 13s) (7 87%) 1.8574\n",
      "Train 198m 7s (- 28m 18s) (7 87%) 1.8316\n",
      "Train 198m 39s (- 28m 22s) (7 87%) 1.9228\n",
      "Train 199m 12s (- 28m 27s) (7 87%) 1.9165\n",
      "Train 199m 44s (- 28m 32s) (7 87%) 1.7990\n",
      "Train 200m 17s (- 28m 36s) (7 87%) 1.9455\n",
      "Train 200m 49s (- 28m 41s) (7 87%) 1.8625\n",
      "Train 201m 21s (- 28m 45s) (7 87%) 1.7375\n",
      "Train 201m 53s (- 28m 50s) (7 87%) 1.8793\n",
      "Train 202m 26s (- 28m 55s) (7 87%) 1.8648\n",
      "Train 202m 58s (- 28m 59s) (7 87%) 1.8596\n",
      "Train 203m 30s (- 29m 4s) (7 87%) 1.9010\n",
      "Train 204m 3s (- 29m 9s) (7 87%) 1.8653\n",
      "Train 204m 35s (- 29m 13s) (7 87%) 1.8275\n",
      "Train 205m 7s (- 29m 18s) (7 87%) 1.9267\n",
      "Train 205m 40s (- 29m 22s) (7 87%) 1.8899\n",
      "Train 206m 12s (- 29m 27s) (7 87%) 1.9516\n",
      "Train 206m 45s (- 29m 32s) (7 87%) 1.8216\n",
      "Train 207m 17s (- 29m 36s) (7 87%) 1.8590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 207m 49s (- 29m 41s) (7 87%) 1.9455\n",
      "Train 208m 22s (- 29m 46s) (7 87%) 1.9143\n",
      "Train 208m 54s (- 29m 50s) (7 87%) 1.9548\n",
      "Train 209m 26s (- 29m 55s) (7 87%) 1.8691\n",
      "Train 209m 59s (- 29m 59s) (7 87%) 1.9505\n",
      "Train 210m 31s (- 30m 4s) (7 87%) 1.9395\n",
      "Train 211m 4s (- 30m 9s) (7 87%) 1.8710\n",
      "Train 211m 36s (- 30m 13s) (7 87%) 1.9303\n",
      "Train 212m 8s (- 30m 18s) (7 87%) 1.9222\n",
      "Train 212m 41s (- 30m 23s) (7 87%) 1.9061\n",
      "Train 213m 13s (- 30m 27s) (7 87%) 1.8539\n",
      "Train 213m 45s (- 30m 32s) (7 87%) 1.9514\n",
      "Train 214m 18s (- 30m 36s) (7 87%) 1.9776\n",
      "Train 214m 50s (- 30m 41s) (7 87%) 1.8090\n",
      "Train 215m 23s (- 30m 46s) (7 87%) 1.9295\n",
      "Train 215m 55s (- 30m 50s) (7 87%) 1.8688\n",
      "Train 216m 27s (- 30m 55s) (7 87%) 1.9834\n",
      "Train 217m 0s (- 31m 0s) (7 87%) 1.9137\n",
      "Train 217m 32s (- 31m 4s) (7 87%) 1.9559\n",
      "Train 218m 5s (- 31m 9s) (7 87%) 1.9796\n",
      "Train 218m 37s (- 31m 13s) (7 87%) 1.8479\n",
      "Train 219m 9s (- 31m 18s) (7 87%) 1.8537\n",
      "Train 219m 41s (- 31m 23s) (7 87%) 1.8348\n",
      "Train 220m 14s (- 31m 27s) (7 87%) 1.8703\n",
      "Train 220m 46s (- 31m 32s) (7 87%) 1.9413\n",
      "Train 221m 18s (- 31m 36s) (7 87%) 1.8407\n",
      "Train 221m 51s (- 31m 41s) (7 87%) 1.8905\n",
      "Train 222m 23s (- 31m 46s) (7 87%) 1.9267\n",
      "Train 222m 55s (- 31m 50s) (7 87%) 1.9578\n",
      "Train 223m 28s (- 31m 55s) (7 87%) 1.8826\n",
      "Train 224m 0s (- 32m 0s) (7 87%) 1.9755\n",
      "Train 224m 33s (- 32m 4s) (7 87%) 1.9741\n",
      "Train 225m 5s (- 32m 9s) (7 87%) 1.8573\n",
      "Train 225m 37s (- 32m 13s) (7 87%) 1.9982\n",
      "Train 226m 10s (- 32m 18s) (7 87%) 1.9188\n",
      "Train 226m 42s (- 32m 23s) (7 87%) 1.9367\n",
      "Train 227m 15s (- 32m 27s) (7 87%) 1.9388\n",
      "Train 227m 47s (- 32m 32s) (7 87%) 1.9479\n",
      "Train 228m 19s (- 32m 37s) (7 87%) 1.9589\n",
      "Val 228m 20s (- 32m 37s) (7 87%) 0.7216\n",
      "Train 228m 33s (- 0m 0s) (8 100%) 0.0705\n",
      "Train 229m 5s (- 0m 0s) (8 100%) 1.8102\n",
      "Train 229m 38s (- 0m 0s) (8 100%) 1.8185\n",
      "Train 230m 10s (- 0m 0s) (8 100%) 1.7853\n",
      "Train 230m 42s (- 0m 0s) (8 100%) 1.7443\n",
      "Train 231m 14s (- 0m 0s) (8 100%) 1.8005\n",
      "Train 231m 47s (- 0m 0s) (8 100%) 1.7852\n",
      "Train 232m 19s (- 0m 0s) (8 100%) 1.8202\n",
      "Train 232m 51s (- 0m 0s) (8 100%) 1.8171\n",
      "Train 233m 24s (- 0m 0s) (8 100%) 1.8848\n",
      "Train 233m 56s (- 0m 0s) (8 100%) 1.8453\n",
      "Train 234m 28s (- 0m 0s) (8 100%) 1.7607\n",
      "Train 235m 1s (- 0m 0s) (8 100%) 1.8471\n",
      "Train 235m 33s (- 0m 0s) (8 100%) 1.8455\n",
      "Train 236m 6s (- 0m 0s) (8 100%) 1.8851\n",
      "Train 236m 38s (- 0m 0s) (8 100%) 1.8110\n",
      "Train 237m 10s (- 0m 0s) (8 100%) 1.7105\n",
      "Train 237m 42s (- 0m 0s) (8 100%) 1.9146\n",
      "Train 238m 15s (- 0m 0s) (8 100%) 1.8466\n",
      "Train 238m 47s (- 0m 0s) (8 100%) 1.9532\n",
      "Train 239m 19s (- 0m 0s) (8 100%) 1.7889\n",
      "Train 239m 52s (- 0m 0s) (8 100%) 1.8351\n",
      "Train 240m 24s (- 0m 0s) (8 100%) 1.8216\n",
      "Train 240m 56s (- 0m 0s) (8 100%) 1.8770\n",
      "Train 241m 29s (- 0m 0s) (8 100%) 1.8728\n",
      "Train 242m 1s (- 0m 0s) (8 100%) 1.8808\n",
      "Train 242m 34s (- 0m 0s) (8 100%) 1.8985\n",
      "Train 243m 6s (- 0m 0s) (8 100%) 1.8670\n",
      "Train 243m 38s (- 0m 0s) (8 100%) 1.8681\n",
      "Train 244m 11s (- 0m 0s) (8 100%) 1.9341\n",
      "Train 244m 43s (- 0m 0s) (8 100%) 1.8695\n",
      "Train 245m 16s (- 0m 0s) (8 100%) 1.8900\n",
      "Train 245m 48s (- 0m 0s) (8 100%) 1.9300\n",
      "Train 246m 21s (- 0m 0s) (8 100%) 1.9953\n",
      "Train 246m 53s (- 0m 0s) (8 100%) 1.9686\n",
      "Train 247m 25s (- 0m 0s) (8 100%) 1.8397\n",
      "Train 247m 58s (- 0m 0s) (8 100%) 1.8381\n",
      "Train 248m 30s (- 0m 0s) (8 100%) 1.8513\n",
      "Train 249m 3s (- 0m 0s) (8 100%) 1.9444\n",
      "Train 249m 35s (- 0m 0s) (8 100%) 1.9289\n",
      "Train 250m 7s (- 0m 0s) (8 100%) 1.9052\n",
      "Train 250m 40s (- 0m 0s) (8 100%) 1.9248\n",
      "Train 251m 13s (- 0m 0s) (8 100%) 1.9993\n",
      "Train 251m 45s (- 0m 0s) (8 100%) 1.8804\n",
      "Train 252m 17s (- 0m 0s) (8 100%) 1.8558\n",
      "Train 252m 50s (- 0m 0s) (8 100%) 1.9051\n",
      "Train 253m 22s (- 0m 0s) (8 100%) 1.9356\n",
      "Train 253m 55s (- 0m 0s) (8 100%) 1.9396\n",
      "Train 254m 27s (- 0m 0s) (8 100%) 1.9398\n",
      "Train 255m 0s (- 0m 0s) (8 100%) 1.9479\n",
      "Train 255m 32s (- 0m 0s) (8 100%) 1.9287\n",
      "Train 256m 4s (- 0m 0s) (8 100%) 1.8883\n",
      "Train 256m 37s (- 0m 0s) (8 100%) 1.8529\n",
      "Train 257m 9s (- 0m 0s) (8 100%) 1.9374\n",
      "Train 257m 42s (- 0m 0s) (8 100%) 1.9208\n",
      "Train 258m 14s (- 0m 0s) (8 100%) 1.8998\n",
      "Train 258m 46s (- 0m 0s) (8 100%) 1.8783\n",
      "Train 259m 19s (- 0m 0s) (8 100%) 1.8315\n",
      "Train 259m 51s (- 0m 0s) (8 100%) 1.8692\n",
      "Train 260m 23s (- 0m 0s) (8 100%) 2.0034\n",
      "Train 260m 56s (- 0m 0s) (8 100%) 1.8881\n",
      "Val 260m 57s (- 0m 0s) (8 100%) 0.7046\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 500\n",
    "encoder2 = EncoderRNN(hidden_size).to(device)\n",
    "decoder2 = DecoderRNN(hidden_size, len(ordered_words_ft_zh)).to(device)\n",
    "\n",
    "plotloss_t2, plotloss_v2 = trainIters(encoder2, decoder2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 300\n",
    "\n",
    "encoder3 = EncoderRNN(hidden_size).to(device)\n",
    "decoder3 = DecoderRNN(hidden_size, len(ordered_words_ft_zh)).to(device)\n",
    "\n",
    "encoder3.load_state_dict(torch.load(model_path + \"encoder_rnn3008.pth\"))\n",
    "decoder3.load_state_dict(torch.load(model_path + \"decoder_rnn3008.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, encoder, decoder):\n",
    "    decoded_words_list = []\n",
    "    with torch.no_grad():\n",
    "        for i, (data1, data2, length1, length2) in enumerate(loader):\n",
    "            input_tensor = data1\n",
    "            input_length = input_tensor.size()[0]\n",
    "            \n",
    "            encoder_hidden = encoder.initHidden(input_length)\n",
    "\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "            \n",
    "            decoder_input = torch.tensor(np.array([[SOS_token]]), device=device)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            decoded_words = []\n",
    "            \n",
    "            for di in range(MAX_LENGTH_EN):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input.reshape(1,1), decoder_hidden)\n",
    "                topv, topi = decoder_output.data.topk(1) \n",
    "                if topi.item() == EOS_token:\n",
    "                    decoded_words.append('<eos>')\n",
    "                    break\n",
    "                else:\n",
    "                    decoded_words.append(idx2words_ft_en[topi.item()])\n",
    "\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                decoder_input = decoder_input.unsqueeze(0)\n",
    "            decoded_words_list.append(decoded_words)\n",
    "        return decoded_words_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_list = evaluate(val_loader2, encoder3, decoder3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score for validation dataset: 6.15811860985386\n"
     ]
    }
   ],
   "source": [
    "predicted_list_nopad = []\n",
    "for ii in range(len(predicted_list)):\n",
    "    line = ''\n",
    "    for jj in predicted_list[ii]:\n",
    "        if jj != '<pad>':\n",
    "            line = line + ' ' + jj\n",
    "    predicted_list_nopad.append(line)\n",
    "\n",
    "for iii in range(len(predicted_list_nopad)):\n",
    "    if predicted_list_nopad[iii][-5:] == '<eos>':\n",
    "        predicted_list_nopad[iii] = predicted_list_nopad[iii][5:-5]\n",
    "    else:\n",
    "        predicted_list_nopad[iii] = predicted_list_nopad[iii][5:]\n",
    "\n",
    "label_list = []\n",
    "for iii in range(len(val_en_indexes_filtered)):\n",
    "    line = ''\n",
    "    for jjj in val_en_indexes_filtered[iii]:\n",
    "        line = line + ' ' + idx2words_ft_en[jjj]\n",
    "    label_list.append(line[5:-5])\n",
    "\n",
    "print('bleu score for validation dataset:', corpus_bleu(predicted_list_nopad, [label_list]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> To order , you can change the soil . \n",
      "> To change the community , you have to change the composition of the soil . \n"
     ]
    }
   ],
   "source": [
    "choice = random.randint(0, len(predicted_list_nopad)-1)\n",
    "print(predicted_list_nopad[choice])\n",
    "print(label_list[choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_list = evaluate(test_loader, encoder3, decoder3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score for test dataset: 4.5332872379845055\n"
     ]
    }
   ],
   "source": [
    "predicted_list_nopad = []\n",
    "for ii in range(len(predicted_list)):\n",
    "    line = ''\n",
    "    for jj in predicted_list[ii]:\n",
    "        if jj != '<pad>':\n",
    "            line = line + ' ' + jj\n",
    "    predicted_list_nopad.append(line)\n",
    "\n",
    "for iii in range(len(predicted_list_nopad)):\n",
    "    if predicted_list_nopad[iii][-5:] == '<eos>':\n",
    "        predicted_list_nopad[iii] = predicted_list_nopad[iii][5:-5]\n",
    "    else:\n",
    "        predicted_list_nopad[iii] = predicted_list_nopad[iii][5:]\n",
    "\n",
    "label_list = []\n",
    "for iii in range(len(test_en_indexes_filtered)):\n",
    "    line = ''\n",
    "    for jjj in test_en_indexes_filtered[iii]:\n",
    "        line = line + ' ' + idx2words_ft_en[jjj]\n",
    "    label_list.append(line[5:-5])\n",
    "\n",
    "print('bleu score for test dataset:', corpus_bleu(predicted_list_nopad, [label_list]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> It s the new new of of .\n",
      "> And try that again and do that for another generation . \n"
     ]
    }
   ],
   "source": [
    "choice = random.randint(0, len(predicted_list_nopad)-1)\n",
    "print(predicted_list_nopad[choice])\n",
    "print(label_list[choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 500\n",
    "\n",
    "encoder3 = EncoderRNN(hidden_size).to(device)\n",
    "decoder3 = DecoderRNN(hidden_size, len(ordered_words_ft_zh)).to(device)\n",
    "\n",
    "encoder3.load_state_dict(torch.load(model_path + \"encoder_rnn5008.pth\"))\n",
    "decoder3.load_state_dict(torch.load(model_path + \"decoder_rnn5008.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score for validation dataset: 6.710148859009111\n",
      "> The Grounds Grounds is to be in the forest in the\n",
      "> So Green Grounds has gone on to plant maybe 20 gardens . \n"
     ]
    }
   ],
   "source": [
    "predicted_list = evaluate(val_loader2, encoder3, decoder3)\n",
    "\n",
    "predicted_list_nopad = []\n",
    "for ii in range(len(predicted_list)):\n",
    "    line = ''\n",
    "    for jj in predicted_list[ii]:\n",
    "        if jj != '<pad>':\n",
    "            line = line + ' ' + jj\n",
    "    predicted_list_nopad.append(line)\n",
    "\n",
    "for iii in range(len(predicted_list_nopad)):\n",
    "    if predicted_list_nopad[iii][-5:] == '<eos>':\n",
    "        predicted_list_nopad[iii] = predicted_list_nopad[iii][5:-5]\n",
    "    else:\n",
    "        predicted_list_nopad[iii] = predicted_list_nopad[iii][5:]\n",
    "\n",
    "label_list = []\n",
    "for iii in range(len(val_en_indexes_filtered)):\n",
    "    line = ''\n",
    "    for jjj in val_en_indexes_filtered[iii]:\n",
    "        line = line + ' ' + idx2words_ft_en[jjj]\n",
    "    label_list.append(line[5:-5])\n",
    "\n",
    "print('bleu score for validation dataset:', corpus_bleu(predicted_list_nopad, [label_list]).score)\n",
    "\n",
    "\n",
    "choice = random.randint(0, len(predicted_list_nopad)-1)\n",
    "print(predicted_list_nopad[choice])\n",
    "print(label_list[choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score for test dataset: 4.273861517547\n",
      "> Who can could bin Laden ? The <unk> <unk> ? \n",
      "> Who could have predicted Double Rainbow or Rebecca Black or <unk> Cat ? \n"
     ]
    }
   ],
   "source": [
    "predicted_list = evaluate(test_loader, encoder3, decoder3)\n",
    "\n",
    "predicted_list_nopad = []\n",
    "for ii in range(len(predicted_list)):\n",
    "    line = ''\n",
    "    for jj in predicted_list[ii]:\n",
    "        if jj != '<pad>':\n",
    "            line = line + ' ' + jj\n",
    "    predicted_list_nopad.append(line)\n",
    "\n",
    "for iii in range(len(predicted_list_nopad)):\n",
    "    if predicted_list_nopad[iii][-5:] == '<eos>':\n",
    "        predicted_list_nopad[iii] = predicted_list_nopad[iii][5:-5]\n",
    "    else:\n",
    "        predicted_list_nopad[iii] = predicted_list_nopad[iii][5:]\n",
    "\n",
    "label_list = []\n",
    "for iii in range(len(test_en_indexes_filtered)):\n",
    "    line = ''\n",
    "    for jjj in test_en_indexes_filtered[iii]:\n",
    "        line = line + ' ' + idx2words_ft_en[jjj]\n",
    "    label_list.append(line[5:-5])\n",
    "\n",
    "print('bleu score for test dataset:', corpus_bleu(predicted_list_nopad, [label_list]).score)\n",
    "\n",
    "choice = random.randint(0, len(predicted_list_nopad)-1)\n",
    "print(predicted_list_nopad[choice])\n",
    "print(label_list[choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_list_nopad = []\n",
    "#for ii in range(len(predicted_list)):\n",
    "    #line = ''\n",
    "    #for jj in predicted_list[ii]:\n",
    "        #if jj != '<pad>':\n",
    "            #line = line + ' ' + jj\n",
    "    #predicted_list_nopad.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for iii in range(len(predicted_list_nopad)):\n",
    "    #if predicted_list_nopad[iii][-5:] != '<eos>':\n",
    "        #predicted_list_nopad[iii] = predicted_list_nopad[iii] + ' <eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = []\n",
    "# for iii in range(len(val_en_indexes_filtered)):\n",
    "#     line = ''\n",
    "#     for jjj in val_en_indexes_filtered[iii]:\n",
    "#         line = line + ' ' + idx2words_ft_en[jjj]\n",
    "#     label_list.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('bleu score for validation dataset:',corpus_bleu(predicted_list_nopad, [label_list]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice = random.randint(0, len(predicted_list_nopad)-1)\n",
    "# print(predicted_list_nopad[choice])\n",
    "# print(label_list[choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_list = evaluate(test_loader, encoder2, decoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_list_nopad = []\n",
    "# for ii in range(len(predicted_list)):\n",
    "#     line = ''\n",
    "#     for jj in predicted_list[ii]:\n",
    "#         if jj != '<pad>':\n",
    "#             line = line + ' ' + jj\n",
    "#     predicted_list_nopad.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for iii in range(len(predicted_list_nopad)):\n",
    "#     if predicted_list_nopad[iii][-5:] != '<eos>':\n",
    "#         predicted_list_nopad[iii] = predicted_list_nopad[iii] + ' <eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = []\n",
    "# for iii in range(len(test_en_indexes_filtered)):\n",
    "#     line = ''\n",
    "#     for jjj in test_en_indexes_filtered[iii]:\n",
    "#         line = line + ' ' + idx2words_ft_en[jjj]\n",
    "#     label_list.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('bleu score for test dataset:', corpus_bleu(predicted_list_nopad, [label_list]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice = random.randint(0, len(predicted_list_nopad)-1)\n",
    "# print(predicted_list_nopad[choice])\n",
    "# print(label_list[choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
